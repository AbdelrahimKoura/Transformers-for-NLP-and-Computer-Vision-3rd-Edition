{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Google Vertex Generative AI Ideation with PaLM 2 and Langchain\n",
        "\n",
        "Copyright 2023, Denis Rothman under the following conditions:   \n",
        "The [original reference notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/examples/prompt-design/ideation.ipynb) was modified and appended for educational purposes. This notebook is an Open Source notebook for educational purposes only.\n",
        "\n",
        "License of the [original reference notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/examples/prompt-design/ideation.ipynb):\n",
        "\n",
        "Copyright 2023 Google LLC\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "     https://www.apache.org/licenses/LICENSE-2.0\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z2IfZvC_guEI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Ideation is the creative process of generating, developing, and communicating new ideas. It is a key part of the design thinking process, and can be used to solve problems, come up with new products or services, or other creative tasks.\n",
        "\n",
        "Generative models are a powerful tool that can be used to boost creativity and innovation. By learning how to use them effectively, you can improve your ability to come up with new ideas and solutions to problems. A key part in this is learning how to structure prompts to use generative models for ideation tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d975e698c9a4"
      },
      "source": [
        "### Objective\n",
        "\n",
        "- Marketing campaign generation\n",
        "- Creating reading comprehension questions\n",
        "- Meme generation\n",
        "- Name generation\n",
        "- General tips and advice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aed92deeb4a0"
      },
      "source": [
        "### Costs\n",
        "\n",
        "This notebook uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI Generative AI Studio\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n",
        "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwfLa-Uzua-4"
      },
      "source": [
        "## Getting Started\n",
        "\n",
        "Run the notebook cell by cell to make sure you have a stable run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a5AEr0lkLKD"
      },
      "source": [
        "### Install Vertex AI SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "148dd6321946"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-aiplatform --upgrade --user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwUbgjm6Jwf6"
      },
      "source": [
        "**Colab only:** Uncomment the following cell to restart the kernel or use the button to restart the kernel. For Vertex AI Workbench you can restart the terminal using the button on top."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Hsqwn4hkLKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46987699-aadd-4617-92a2-eead0865012c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# # Automatically restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure the notebook was restarted if you encounter an issue when initializing your PROJECT ID"
      ],
      "metadata": {
        "id": "ubCc_2hAp4GX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe7OuYuGkLKF"
      },
      "source": [
        "### Authenticating your notebook environment\n",
        "* If you are using **Colab** to run this notebook, uncomment the cell below and continue.\n",
        "* If you are using **Vertex AI Workbench**, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9Gx2SAZkLKF"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieving your Google Cloud PROJECT_ID\n",
        "This is only necessary to initialize the Vertex AI SDK.  \n",
        "You don't need to use Google Drive. You can use another\n",
        "methode to retrieve your Google Cloud PROJECT_ID or enter it\n",
        "directly in the notebook."
      ],
      "metadata": {
        "id": "8FGLToNxlgwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive for the entire notebook\n",
        "# goal: read and write files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj_iQ3avmF8I",
        "outputId": "402fd696-c408-43a4-9a02-89b1eaa9656a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Store your Project ID  in a file and read it(you can type it directly in the notebook but it will be visible for somebody next to you)\n",
        "f = open(\"drive/MyDrive/files/GPID.txt\", \"r\")\n",
        "PROJECT_ID=f.readline()\n",
        "f.close()"
      ],
      "metadata": {
        "id": "s4T-pahml7bS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "960505627ddf"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vfALIMrJwf-"
      },
      "source": [
        "**Colab only:** Uncomment the following cell to initialize the Vertex AI SDK. For Vertex AI Workbench, you don't need to run this.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rc3ZSm7FJwf-"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "#PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview.language_models import TextGenerationModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP76a2la7O-a"
      },
      "source": [
        "### Import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7isig7e07O-a"
      },
      "outputs": [],
      "source": [
        "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoYLyYlLxN72"
      },
      "source": [
        "## Ideation Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km9MirdFua-5"
      },
      "source": [
        "### Marketing campaign generation\n",
        "\n",
        "In this example, our generation example will involve the process of creating new cookie recipes. Let's see how this can be done using the PaLM API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2v5Pdkdua-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd031da6-6f15-431c-9908-e57f638ed2ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Headline:** Sustainable fashion: The future of fashion is here\n",
            "\n",
            "**Body:**\n",
            "\n",
            "The fashion industry is one of the most polluting industries in the world. It produces a huge amount of waste, and it uses a lot of resources, including water, energy, and chemicals.\n",
            "\n",
            "But there is a growing movement towards sustainable fashion. This is fashion that is produced in a way that is less harmful to the environment and to people.\n",
            "\n",
            "There are many ways to make fashion more sustainable. One way is to use recycled materials. Another way is to use less water and energy in the production process. And another way is to pay workers a fair wage.\n",
            "\n",
            "Sustainable fashion is not just about making the clothes themselves more sustainable. It's also about changing the way we think about fashion. We need to start thinking about fashion as a long-term investment, not as a disposable commodity.\n",
            "\n",
            "We need to buy less, and we need to buy better quality clothes. And we need to take care of our clothes so that they last longer.\n",
            "\n",
            "If we all make a small change, we can make a big difference. We can help to create a more sustainable fashion industry, and we can help to protect the planet for future generations.\n",
            "\n",
            "**Call to action:**\n",
            "\n",
            "Start shopping for sustainable fashion today. And tell your friends and family about it too. Together, we can make a difference.\n",
            "\n",
            "**Image:**\n",
            "\n",
            "A photo of a woman wearing a sustainable fashion outfit. The outfit is made from recycled materials and the woman is smiling.\n",
            "\n",
            "**Tagline:**\n",
            "\n",
            "Sustainable fashion: The future of fashion is here.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Generate a marketing campaign for sustainability and fashion\"\n",
        "\n",
        "print(\n",
        "    generation_model.predict(\n",
        "        prompt, temperature=0.2, max_output_tokens=1024, top_k=40, top_p=0.8\n",
        "    ).text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DC1rKWlua-6"
      },
      "source": [
        "### Creating reading comprehension questions\n",
        "\n",
        "Reading comprehension tests are often used in schools and universities to assess a student's reading skills. You can use the PaLM API to generate some example questions to test a person's understanding of a provided passage of text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Shb54o4vua-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1526d4de-9056-42ad-b433-4350f50bf8f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. What is the Amazon rainforest?\n",
            "2. What are the major biomes in the Amazon rainforest?\n",
            "3. What are the major ethnic groups in the Amazon rainforest?\n",
            "4. What are the major climate fluctuations in the Amazon rainforest?\n",
            "5. What are the major sources of phosphorus for the Amazon rainforest?\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "Generate 5 questions that test a reader's comprehension of the following text.\n",
        "\n",
        "Text:\n",
        "The Amazon rainforest, also called Amazon jungle or Amazonia, is a moist broadleaf tropical rainforest in the Amazon biome that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 km2 (2,700,000 sq mi), of which 5,500,000 km2 (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations and 3,344 formally acknowledged indigenous territories.\n",
        "\n",
        "The majority of the forest, 60%, is in Brazil, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Bolivia, Ecuador, French Guiana, Guyana, Suriname, and Venezuela. Four nations have \"Amazonas\" as the name of one of their first-level administrative regions, and France uses the name \"Guiana Amazonian Park\" for French Guiana's protected rainforest area. The Amazon represents over half of the planet's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees in about 16,000 species.\n",
        "\n",
        "More than 30 million people of 350 different ethnic groups live in the Amazon, which are subdivided into 9 different national political systems and 3,344 formally acknowledged indigenous territories. Indigenous peoples make up 9% of the total population, and 60 of the groups remain largely isolated.\n",
        "\n",
        "The rainforest likely formed during the Eocene era (from 56 million years to 33.9 million years ago). It appeared following a global reduction of tropical temperatures when the Atlantic Ocean had widened sufficiently to provide a warm, moist climate to the Amazon basin. The rainforest has been in existence for at least 55 million years, and most of the region remained free of savanna-type biomes at least until the current ice age when the climate was drier and savanna more widespread.\n",
        "\n",
        "Following the Cretaceous–Paleogene extinction event, the extinction of the dinosaurs and the wetter climate may have allowed the tropical rainforest to spread out across the continent. From 66 to 34 Mya, the rainforest extended as far south as 45°. Climate fluctuations during the last 34 million years have allowed savanna regions to expand into the tropics. During the Oligocene, for example, the rainforest spanned a relatively narrow band. It expanded again during the Middle Miocene, then retracted to a mostly inland formation at the last glacial maximum. However, the rainforest still managed to thrive during these glacial periods, allowing for the survival and evolution of a broad diversity of species.\n",
        "\n",
        "Aerial view of the Amazon rainforest\n",
        "During the mid-Eocene, it is believed that the drainage basin of the Amazon was split along the middle of the continent by the Púrus Arch. Water on the eastern side flowed toward the Atlantic, while to the west water flowed toward the Pacific across the Amazonas Basin. As the Andes Mountains rose, however, a large basin was created that enclosed a lake; now known as the Solimões Basin. Within the last 5–10 million years, this accumulating water broke through the Púrus Arch, joining the easterly flow toward the Atlantic.\n",
        "\n",
        "There is evidence that there have been significant changes in the Amazon rainforest vegetation over the last 21,000 years through the last glacial maximum (LGM) and subsequent deglaciation. Analyses of sediment deposits from Amazon basin paleolakes and the Amazon Fan indicate that rainfall in the basin during the LGM was lower than for the present, and this was almost certainly associated with reduced moist tropical vegetation cover in the basin. In present day, the Amazon receives approximately 9 feet of rainfall annually. There is a debate, however, over how extensive this reduction was. Some scientists argue that the rainforest was reduced to small, isolated refugia separated by open forest and grassland; other scientists argue that the rainforest remained largely intact but extended less far to the north, south, and east than is seen today. This debate has proved difficult to resolve because the practical limitations of working in the rainforest mean that data sampling is biased away from the center of the Amazon basin, and both explanations are reasonably well supported by the available data.\n",
        "\n",
        "Sahara Desert dust windblown to the Amazon\n",
        "More than 56% of the dust fertilizing the Amazon rainforest comes from the Bodélé depression in Northern Chad in the Sahara desert. The dust contains phosphorus, important for plant growth. The yearly Sahara dust replaces the equivalent amount of phosphorus washed away yearly in Amazon soil from rains and floods.\n",
        "\n",
        "NASA's CALIPSO satellite has measured the amount of dust transported by wind from the Sahara to the Amazon: an average of 182 million tons of dust are windblown out of the Sahara each year, at 15 degrees west longitude, across 2,600 km (1,600 mi) over the Atlantic Ocean (some dust falls into the Atlantic), then at 35 degrees West longitude at the eastern coast of South America, 27.7 million tons (15%) of dust fall over the Amazon basin (22 million tons of it consisting of phosphorus), 132 million tons of dust remain in the air, 43 million tons of dust are windblown and falls on the Caribbean Sea, past 75 degrees west longitude.\n",
        "\n",
        "CALIPSO uses a laser range finder to scan the Earth's atmosphere for the vertical distribution of dust and other aerosols. CALIPSO regularly tracks the Sahara-Amazon dust plume. CALIPSO has measured variations in the dust amounts transported – an 86 percent drop between the highest amount of dust transported in 2007 and the lowest in 2011.\n",
        "A possibility causing the variation is the Sahel, a strip of semi-arid land on the southern border of the Sahara. When rain amounts in the Sahel are higher, the volume of dust is lower. The higher rainfall could make more vegetation grow in the Sahel, leaving less sand exposed to winds to blow away.[25]\n",
        "\n",
        "Amazon phosphorus also comes as smoke due to biomass burning in Africa.\n",
        "\n",
        "Questions:\n",
        "\"\"\"\n",
        "\n",
        "print(\n",
        "    generation_model.predict(\n",
        "        prompt, temperature=0.2, max_output_tokens=1024, top_k=40, top_p=0.8\n",
        "    ).text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCcCMhbOua-7"
      },
      "source": [
        "### Meme generation\n",
        "\n",
        "The goal is to obtain a text for a text-to-image meme"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Give me 5 sustainability image generation ideas associated with nature with no humans in the text and a beautiful rain forest for text-to-image generation:\"\n",
        "\n",
        "# Create an empty list to store the outputs\n",
        "outputs = []\n",
        "\n",
        "# Generate 5 outputs\n",
        "output = generation_model.predict(\n",
        "  prompt, temperature=0.2, max_output_tokens=1024, top_k=1, top_p=0.8\n",
        " ).text\n",
        "outputs.append(output)\n",
        "\n",
        "# Print the outputs\n",
        "for output in outputs:\n",
        "    print(output)"
      ],
      "metadata": {
        "id": "5gN3Aw5WsxF_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fd98e25-bbf9-46bd-b04a-b56ccdae798d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. A lush green forest with a winding river running through it. The trees are tall and majestic, and the leaves are a vibrant green. The river is clear and blue, and it reflects the sunlight that shines through the trees.\n",
            "2. A beautiful meadow with a variety of flowers in bloom. The flowers are all different colors, and they create a beautiful and colorful landscape. The meadow is also home to a variety of animals, including birds, butterflies, and rabbits.\n",
            "3. A snow-capped mountain range. The mountains are covered in snow, and they tower over the landscape. The snow is a beautiful white, and it contrasts nicely with the green trees and blue sky.\n",
            "4. A coral reef. The coral reef is home to a variety of sea creatures, including fish, turtles, and dolphins. The coral is a vibrant color, and it creates a beautiful underwater landscape.\n",
            "5. A tropical rainforest. The rainforest is home to a variety of plants and animals, including trees, birds, and monkeys. The rainforest is a lush and green environment, and it is full of life.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Meme output processing"
      ],
      "metadata": {
        "id": "U3b7211lwRJj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the outputs for the text-to-image generation"
      ],
      "metadata": {
        "id": "bryeIooSudwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"image2text.txt\", \"w\") as f:\n",
        "    for output in outputs:\n",
        "        f.write(output + \"\\n\")"
      ],
      "metadata": {
        "id": "Mmt6PJp-tdKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing the text-to-image function"
      ],
      "metadata": {
        "id": "Z9oBiB1VuOAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"image2text.txt\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "for line in lines:\n",
        "    prompt = line.strip()\n",
        "    print(prompt)"
      ],
      "metadata": {
        "id": "u9kEnnrFuXXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0639104b-9822-4eb6-8bf5-1bc910e094ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. A lush green forest with a winding river running through it. The trees are tall and majestic, and the leaves are a vibrant green. The river is clear and blue, and it reflects the sunlight that shines through the trees.\n",
            "2. A beautiful meadow with a variety of flowers in bloom. The flowers are all different colors, and they create a beautiful and colorful landscape. The meadow is also home to a variety of animals, including birds, butterflies, and rabbits.\n",
            "3. A snow-capped mountain range. The mountains are covered in snow, and they tower over the landscape. The snow is a beautiful white, and it contrasts nicely with the green trees and blue sky.\n",
            "4. A coral reef. The coral reef is home to a variety of sea creatures, including fish, turtles, and dolphins. The coral is a vibrant color, and it creates a beautiful underwater landscape.\n",
            "5. A tropical rainforest. The rainforest is home to a variety of plants and animals, including trees, birds, and monkeys. The rainforest is a lush and green environment, and it is full of life.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the output begins with numbers such as \"1.\", we need to strip the line to make sure the prompt does not contain numbers."
      ],
      "metadata": {
        "id": "777SMtYUvJZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "with open(\"image2text.txt\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "for line in lines:\n",
        "    prompt = line.strip()\n",
        "    prompt = re.sub(r\"\\d+\\. \", \"\", prompt)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "id": "hBaNYevgvTtq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce0bef6b-84b8-494d-f36e-aac7129c24e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A lush green forest with a winding river running through it. The trees are tall and majestic, and the leaves are a vibrant green. The river is clear and blue, and it reflects the sunlight that shines through the trees.\n",
            "A beautiful meadow with a variety of flowers in bloom. The flowers are all different colors, and they create a beautiful and colorful landscape. The meadow is also home to a variety of animals, including birds, butterflies, and rabbits.\n",
            "A snow-capped mountain range. The mountains are covered in snow, and they tower over the landscape. The snow is a beautiful white, and it contrasts nicely with the green trees and blue sky.\n",
            "A coral reef. The coral reef is home to a variety of sea creatures, including fish, turtles, and dolphins. The coral is a vibrant color, and it creates a beautiful underwater landscape.\n",
            "A tropical rainforest. The rainforest is home to a variety of plants and animals, including trees, birds, and monkeys. The rainforest is a lush and green environment, and it is full of life.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is for Google Drive usage for a project"
      ],
      "metadata": {
        "id": "ub-BaKinwCPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp image2text.txt  \"drive/MyDrive/files/image2text.txt\""
      ],
      "metadata": {
        "id": "zShNtMn0wBYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1nSLoW7ua-8"
      },
      "source": [
        "### Name generation\n",
        "\n",
        "Name generation is useful in a variety of scenarios, such as creating new characters for a story or naming a new product or company. You can generate ideas for names of a specified entity using the PaLM API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLnUrgs8ua-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61b17331-b750-4226-bd32-0ab12448962b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Eco-chic\n",
            "* Sustainable fashion\n",
            "* Green fashion\n",
            "* Ethical fashion\n",
            "* Zero-waste fashion\n",
            "* Upcycled fashion\n",
            "* Repurposed fashion\n",
            "* Vintage fashion\n",
            "* Thrifted fashion\n"
          ]
        }
      ],
      "source": [
        "prompt = \"What's a good name for a new fashion dressing style that associates the colors of a dress with sustainability?\"\n",
        "\n",
        "print(\n",
        "    generation_model.predict(\n",
        "        prompt, temperature=0.2, max_output_tokens=256, top_k=1, top_p=0.8\n",
        "    ).text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5Ca5Btvua-8"
      },
      "source": [
        "### General tips and advice\n",
        "\n",
        "Below is an example of using the PaLM API to get tips and advice on general topics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFy4ix6Cua-9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d787025a-07a8-48b5-e2af-2c1d9fd2ba43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Use clear and concise language.\n",
            "* Avoid using jargon or technical terms that may not be familiar to everyone.\n",
            "* Be specific about what you want the model to generate. For example, instead of asking the model to describe an image, you could ask it to write a caption for the image.\n",
            "* Provide the model with as much context as possible. This could include information about the image, such as the location where it was taken, the time of day, or the people or objects in the image.\n",
            "* Use positive and encouraging feedback when training the model. This will help the model to learn and improve its performance.\n",
            "\n",
            "Here are some examples of prompts that you could use for image-to-text models for sustainability:\n",
            "\n",
            "* Describe the environmental impact of this image.\n",
            "* What are some ways to reduce the environmental impact of this image?\n",
            "* What are some sustainable alternatives to the products or activities depicted in this image?\n",
            "* How can we make this image more sustainable?\n",
            "* What are the positive and negative environmental impacts of this image?\n"
          ]
        }
      ],
      "source": [
        "prompt = \"What are some strategies for writing prompts for image-to-text models for sustainability?\"\n",
        "\n",
        "print(\n",
        "    generation_model.predict(\n",
        "        prompt, temperature=0.2, max_output_tokens=1024, top_k=1, top_p=0.8\n",
        "    ).text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generative AI with Langchain\n",
        "Copyright 2023, Denis Rothman, MIT License\n",
        "\n",
        "The original\n",
        "[Google Reference notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/examples/document-qa/question_answering_large_documents_langchain.ipynb) provided Langchain implementation for similarity search in a document.\n",
        "\n",
        "**Google License** for the reference Google Notebook:\n",
        "\n",
        "Copyright 2023 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        " Unless required by applicable law or agreed to in writing, software\n",
        " distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        " limitations under the License.\n",
        "\n",
        "\n",
        "\n",
        "**Langchain references**   \n",
        "[Langchain home](https://www.langchain.com/)   \n",
        "[LangChain is a framework for developing applications powered by language models](https://python.langchain.com/docs/get_started/introduction.html)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uYxPnFpK7exh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVPNFqVm94RR"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "sTn6zOwo7tTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2zvVNgj8T9z"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "import warnings\n",
        "from pathlib import Path as p\n",
        "from pprint import pprint\n",
        "\n",
        "import pandas as pd\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.llms import VertexAI\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAGaTjPVTmhP"
      },
      "source": [
        "### Import models\n",
        "\n",
        "You load the pre-trained text and embeddings generation model called `text-bison@001` and `textembedding-gecko@001` respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITUmZiNZcMUW"
      },
      "outputs": [],
      "source": [
        "vertex_llm_text = VertexAI(model_name=\"text-bison@001\")\n",
        "vertex_embeddings = VertexAIEmbeddings(model_name=\"textembedding-gecko@001\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxgiio5qTSGG"
      },
      "source": [
        "## Question Answering with large documents\n",
        "\n",
        "Large language models (LLMs) are powerful tools that can be used to answer a wide range of questions about large document base. However, there are some challenges associated with using large language model (LLM) for question answering. One of these challenges is related with the limited knowledge of LLMs models, especially when documents are specific of some context.\n",
        "\n",
        "One way to address this limitation is to give more information about documents using retrieval augmented generation. Retrieval augmented generation is a technique for using a large language model (LLM) to answer questions about documents it was not trained on. The basic idea is to first retrieve any relevant documents from a corpus called context, then pass those documents along with the original question to the LLM. The LLM will then generate a response that is informed by the information in the retrieved documents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZkLDRTjTcfm"
      },
      "source": [
        "### Ingest documents\n",
        "\n",
        "To begin, you will need to download a files that are required for the summarizing tasks below."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Reference PDF on Climate Change](https://climate.ec.europa.eu/system/files/2018-06/youth_magazine_en.pdf)\n",
        "\n",
        "If this link doesn't work due to a website modification, try another pdf file."
      ],
      "metadata": {
        "id": "2bWzYT9VVVqd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7H0zINHpTaSu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2be4787-ec17-44a8-a765-bda0de472062"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/data/youth_magazine_en.pdf',\n",
              " <http.client.HTTPMessage at 0x7989ec3b2740>)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "data_folder = p.cwd() / \"data\"\n",
        "p(data_folder).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "#pdf_url = \"https://services.google.com/fh/files/misc/practitioners_guide_to_mlops_whitepaper.pdf\"\n",
        "pdf_url = \"https://climate.ec.europa.eu/system/files/2018-06/youth_magazine_en.pdf\"\n",
        "pdf_file = str(p(data_folder, pdf_url.split(\"/\")[-1]))\n",
        "\n",
        "urllib.request.urlretrieve(pdf_url, pdf_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JELITHdBhnf0"
      },
      "source": [
        "### Extract text from the PDF\n",
        "\n",
        "You use an `PdfReader` to extract the text from our scanned documents.\n",
        "\n",
        "[A pure-python PDF library capable of splitting, merging, cropping, and transforming PDF files](https://pypi.org/project/pypdf/)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "Z6bpsnjl9W9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3INtovxreI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51d8cb0e-501f-471d-e9b7-36712f070afa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4science bit\n",
            "Earth’s climate has changed throughout history, gradually \n",
            "getting hotter or colder for long periods of time. In the \n",
            "last million years there have been about 10 ice ages, \n",
            "with much warmer periods in between. These changes were \n",
            "the result of natural causes, such as changes in the tilt of the planet, the sun’s activity and ocean currents. \n",
            "But the changes we are seeing today are different – and we are responsible! By releasing more of the gases \n",
            "that trap heat into the atmosphere, we are causing the temperature on Earth to rise very quickly. Heat comes in …\n",
            "and can’t  get out!\n",
            "NEITHER CAN I …\n",
            "The greenhouse \n",
            "effect  \n",
            "When sunlight hits the Earth’s \n",
            "surface, some of this energy \n",
            "is absorbed and warms the \n",
            "ground and the oceans. The rest \n",
            "of the energy can escape back \n",
            "into space, but some of it is trapped \n",
            "in the atmosphere and warms \n",
            "the Earth. This is called the \n",
            "'greenhouse effect', because the \n",
            "atmosphere acts like the glass \n",
            "in a greenhouse – warming the \n",
            "inside. This greenhouse effect \n",
            "happens because the Earth's \n",
            "atmosphere contains gases such \n",
            "as water vapour, carbon dioxide, \n",
            "methane and nitrous oxide \n",
            "(these are called greenhouse \n",
            "gases). The greenhouse effect \n",
            "is what normally keeps our planet \n",
            "at a comfortable temperature. \n",
            "However, human activities are \n",
            "increasing the amount \n",
            "of greenhouse gases in the \n",
            "atmosphere which makes the \n",
            "greenhouse effect stronger and \n",
            "increases the temperature \n",
            "of the Earth.What’s causing \n",
            "climate change?  \n",
            "Climate change is caused by the \n",
            "increase in the Earth's temperature \n",
            "(global warming) which comes \n",
            "from adding more greenhouse \n",
            "gases to the atmosphere than \n",
            "those occurring naturally. These \n",
            "extra greenhouse gases mainly \n",
            "come from burning fossil fuels \n",
            "to produce energy, as well as from \n",
            "other human activities like cutting \n",
            "down rainforests, agriculture, \n",
            "farming livestock and the \n",
            "production of chemicals.Weather \n",
            "vs. climate\n",
            "Weather and climate are different \n",
            "but related things. Weather \n",
            "describes the day-to-day conditions \n",
            "in a particular place – for example, \n",
            "it can be cloudy and wet one \n",
            "day  and sunny the next. 'Climate' \n",
            "describes the average weather \n",
            "conditions in a place over relatively \n",
            "long periods of time (e.g. 30 years). \n",
            "Deserts, for example, have a hot \n",
            "and dry climate, while the Arctic \n",
            "and Antarctic regions are cold \n",
            "and dry.\n",
            "Getting warmer \n",
            "In 2016, the Earth was around 1.1 °C hotter than it was in the late \n",
            "19th century – and the average global temperature is set to rise \n",
            "even more over the next century. 1.1 °C may not sound like much, \n",
            "but consider this:\n",
            " Most of the warming so far happened in the past \n",
            "few decades, so the temperature rise is speeding up.\n",
            " Don’t forget, this is an average increase: some places \n",
            "have become much warmer and others colder. For example, \n",
            "the Arctic has become substantially warmer over the last \n",
            "60 years and could be ice-free in summer by 2040. Europe \n",
            "is warming faster than other areas of the world. \n",
            " According to some studies, Earth's temperature during \n",
            "the last ice age was only around 4 °C colder than in the \n",
            "late 19th century.Did you know? \n",
            "Levels of carbon dioxide (CO2) \n",
            "in the atmosphere are higher today \n",
            "than at any time during the last \n",
            "800,000 years. \n",
            " The\n"
          ]
        }
      ],
      "source": [
        "pdf_loader = PyPDFLoader(pdf_file)\n",
        "pages = pdf_loader.load_and_split()\n",
        "#print(pages[3].page_content)\n",
        "print(pages[5].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soNkAis3F3DT"
      },
      "source": [
        "### Prompt Design\n",
        "\n",
        "In a Q&A system, you define a question and the associated prompt.\n",
        "\n",
        "The question is simply a string that represents the question that the application will be asked to answer. In this case, the question is ```\"What is Experimentation?\"```\n",
        "\n",
        "The prompt is a string that contains the context that the application will use to generate an answer to the question. In this case, the prompt is\n",
        "\n",
        "```\n",
        "Answer the question as precise as possible using the provided context.\n",
        "If the answer is not contained in the context, say \"answer not available in context\" \\n\\n\n",
        "\n",
        "Context: \\n {context}?\\n\n",
        "Question: \\n {question} \\n\n",
        "Answer:\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EGBdXZWF3DT"
      },
      "outputs": [],
      "source": [
        "question = \"What is the greenhouse effect?\"\n",
        "prompt_template = \"\"\"Answer the question as precise as possible using the provided context. If the answer is\n",
        "                    not contained in the context, say \"answer not available in context\" \\n\\n\n",
        "                    Context: \\n {context}?\\n\n",
        "                    Question: \\n {question} \\n\n",
        "                    Answer:\n",
        "                  \"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O30DdYUZEP6p"
      },
      "source": [
        "**Consideration**: So far, you use both part of the document or the entire document as the context to answer your specific question. Both cases have several limitations, including incomplete context and slow to query, especially for large context.\n",
        "\n",
        "Similarity search over a vector database, is a newer approach that addresses these limitations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dw-aHBJN7DN"
      },
      "source": [
        "### Q&A with similarity search\n",
        "\n",
        "With similarity search over a vector database, each piece of context is represented as a vector. These vectors are then stored in a database. When a user asks a question, the system first calculates the similarity between the question and the vectors in the database. The most similar vectors are then used to fetch the context that is relevant to the question.\n",
        "\n",
        "This approach has several advantages including more accurate context with respect of the user's question.\n",
        "\n",
        "In this case, you use `Chroma` an in-memory open-source embedding database to create similarity search index."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydX1I_P-ToEj"
      },
      "source": [
        "#### Context Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01IYPsj8KVVh"
      },
      "source": [
        "Split the document content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLUqrLDnLuTH"
      },
      "outputs": [],
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=10000, chunk_overlap=0)\n",
        "context = \"\\n\\n\".join(str(p.page_content) for p in pages)\n",
        "texts = text_splitter.split_text(context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKY_56ChClcK"
      },
      "source": [
        "Then, create the similarity search index using `Chroma`\n",
        "\n",
        "[Chroma - the open-source embedding database](https://pypi.org/project/chromadb/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "0Vp_6gWUCKCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLAMaLkgNG5U"
      },
      "outputs": [],
      "source": [
        "vector_index = Chroma.from_texts(texts, vertex_embeddings).as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1c8Av35K_sl"
      },
      "source": [
        "Next, retrieve relevant context using the original question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgxD6ezEOAgL"
      },
      "outputs": [],
      "source": [
        "docs = vector_index.get_relevant_documents(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU4sV359LNTM"
      },
      "source": [
        "#### MapReduce method\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KDDYnK6yZOu"
      },
      "source": [
        "\n",
        "\n",
        "With `MapReduce`, you can overcome the context limit. It involves dividing the document into chunks, running an initial prompt on each chunk, and then combining the results of the initial prompts using a different prompt.\n",
        "\n",
        "In LangChain, you can use `MapReduceDocumentsChain` as part of the `load_qa_chain` method with `map_reduce` as `chain_type` of your chain.\n",
        "\n",
        "The `load_qa_chain` with `map_reduce` as `chain_type` requires two prompts, question and a combine prompts.\n",
        "\n",
        "The question prompt is used to ask the LLM to answer a question based on the provided context. In this case, the `question_prompt` is\n",
        "\n",
        "```\n",
        "Answer the question as precise as possible using the provided context. \\n\\n\n",
        "Context: \\n {context} \\n\n",
        "Question: \\n {question} \\n\n",
        "Answer:\n",
        "```\n",
        "\n",
        "The combine prompt object is used to combine the extracted content and the question to create a final answer. In this case, the `combine_prompt` is\n",
        "\n",
        "```\n",
        "Given the extracted content and the question, create a final answer.\n",
        "If the answer is not contained in the context, say \"answer not available in context. \\n\\n\n",
        "Summaries: \\n {summaries}?\\n\n",
        "Question: \\n {question} \\n\n",
        "Answer:\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJeB8gG-3OIB"
      },
      "outputs": [],
      "source": [
        "question_prompt_template = \"\"\"\n",
        "                    Answer the question as precise as possible using the provided context. \\n\\n\n",
        "                    Context: \\n {context} \\n\n",
        "                    Question: \\n {question} \\n\n",
        "                    Answer:\n",
        "                    \"\"\"\n",
        "question_prompt = PromptTemplate(\n",
        "    template=question_prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "# summaries is required. a bit confusing.\n",
        "combine_prompt_template = \"\"\"Given the extracted content and the question, create a final answer.\n",
        "If the answer is not contained in the context, say \"answer not available in context. \\n\\n\n",
        "Summaries: \\n {summaries}?\\n\n",
        "Question: \\n {question} \\n\n",
        "Answer:\n",
        "\"\"\"\n",
        "combine_prompt = PromptTemplate(\n",
        "    template=combine_prompt_template, input_variables=[\"summaries\", \"question\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MapReduce is a programming model and an associated implementation for processing and generating big data sets with a parallel, distributed algorithm on a cluster. A MapReduce program is composed of a map procedure, which performs filtering and sorting, and a reduce method, which performs a summary operation.\n",
        "\n",
        "The code you provided, `map_reduce_chain = load_qa_chain(vertex_llm_text, chain_type=\"map_reduce\", return_intermediate_steps=True, question_prompt=question_prompt, combine_prompt=combine_prompt)`, uses the MapReduce programming model to create a map-reduce chain, which is a type of chain that can be used to process large amounts of text.\n",
        "\n",
        "The code first loads the vertex_llm_text, which is a large language model that will be used to process the text. The `chain_type` parameter is set to \"map_reduce\", which tells the library to create a map-reduce chain. The `return_intermediate_steps` parameter is set to `True`, which tells the library to return the intermediate steps of the chain. The `question_prompt` and `combine_prompt` parameters are used to specify the prompts that will be used to generate the questions and answers for the chain.\n",
        "\n",
        "The `load_qa_chain()` function returns a map-reduce chain object. This object can be used to process text and answer questions.\n",
        "\n",
        "Here is a breakdown of the code:\n",
        "\n",
        "```python\n",
        "map_reduce_chain = load_qa_chain(\n",
        "    vertex_llm_text,\n",
        "    chain_type=\"map_reduce\",\n",
        "    return_intermediate_steps=True,\n",
        "    question_prompt=question_prompt,\n",
        "    combine_prompt=combine_prompt,\n",
        ")\n",
        "```\n",
        "\n",
        "* `load_qa_chain()` is the function that is used to load the map-reduce chain.\n",
        "* `vertex_llm_text` is the large language model that will be used to process the text.\n",
        "* `chain_type` is the type of chain that will be created. In this case, the chain type is \"map_reduce\".\n",
        "* `return_intermediate_steps` is a boolean value that specifies whether or not the intermediate steps of the chain should be returned. In this case, the intermediate steps will be returned.\n",
        "* `question_prompt` is the prompt that will be used to generate the questions for the chain.\n",
        "* `combine_prompt` is the prompt that will be used to combine the answers from the different steps of the chain.\n",
        "\n"
      ],
      "metadata": {
        "id": "9nZ8vBzVIe2z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8IdKzmGade1"
      },
      "source": [
        "After you define expected prompt, you initialize a `load_qa_chain` chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmkGiHXB2ID3"
      },
      "outputs": [],
      "source": [
        "map_reduce_chain = load_qa_chain(\n",
        "    vertex_llm_text,\n",
        "    chain_type=\"map_reduce\",\n",
        "    return_intermediate_steps=True,\n",
        "    question_prompt=question_prompt,\n",
        "    combine_prompt=combine_prompt,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally you answer your question based on the context you retrive with embeddings database and the input question.\n"
      ],
      "metadata": {
        "id": "M_BCM5kCFNYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import transformers python package. This is needed in order to calculate get_token_ids."
      ],
      "metadata": {
        "id": "sX6WHAI_Hc6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "Juq71O_PHflu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrO635SkPdkR"
      },
      "outputs": [],
      "source": [
        "map_reduce_embeddings_outputs = map_reduce_chain(\n",
        "    {\"input_documents\": docs, \"question\": question}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQozAWI3lkXp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba0faebd-e462-4d49-c71b-17f872c70124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The greenhouse effect is the process by which gases in the Earth's atmosphere trap heat, keeping the planet warm. The most important greenhouse gas is carbon dioxide (CO2).\n"
          ]
        }
      ],
      "source": [
        "print(map_reduce_embeddings_outputs[\"output_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing the text for text-to-image"
      ],
      "metadata": {
        "id": "AJV7O72wWuuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_text=map_reduce_embeddings_outputs[\"output_text\"]\n",
        "first_sentence = output_text.split('.')[0]\n",
        "print(first_sentence + '.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNf6YS__WuAh",
        "outputId": "e29527b3-df3b-4856-d2cb-c4798c1d2a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The greenhouse effect is the process by which gases in the Earth's atmosphere trap heat, keeping the planet warm.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the file in write mode and write the first sentence to it\n",
        "with open('Langchain_image2txt.txt', 'w') as file:\n",
        "    file.write(first_sentence)"
      ],
      "metadata": {
        "id": "vQx3XpI7XTsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "File to Google Drive\n",
        "\n",
        "Modify code for another location"
      ],
      "metadata": {
        "id": "EE0F-3G3YW4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp Langchain_image2txt.txt  \"drive/MyDrive/files/Langchain_image2txt.txt\""
      ],
      "metadata": {
        "id": "J08Tk0mPYjDb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-11.m108",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}