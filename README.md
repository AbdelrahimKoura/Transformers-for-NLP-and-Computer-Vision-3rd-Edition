# Transformers for Natural Language Processing and Computer Vision: Take Generative AI and LLMs to the next level with Hugging Face, Google Vertex AI, ChatGPT, GPT-4V, and DALL-E 3 3rd Edition<br>
by Denis Rothman <br><br>
<img src="https://github.com/Denis2054/Transformers_3rd_Edition/blob/main/Transformers_3rd_Edition.jpg?raw=tru" alt="drawing" width="400"/>

Last updated: March 4, 2024  
Look for the  üê¨ for bonus notebooks! 

# Transformers-for-NLP-and-Computer-Vision-3rd-Edition
This is the code repository for [Transformers for Natural Language Processing and Computer Vision](https://www.amazon.com/Transformers-Natural-Language-Processing-Computer/dp/1805128728/), published by Packt.

**Explore Generative AI and Large Language Models with Hugging Face, ChatGPT, GPT-4V, and DALL-E 3**

## About the book
Transformers for Natural Language Processing and Computer Vision, Third Edition, explores **Large Language Model** (**LLM**) architectures, applications, and various platforms (Hugging Face, OpenAI, and Google Vertex AI) used for **Natural Language Processing** (**NLP**) and **Computer Vision** (**CV**).

Dive into generative vision transformers and multimodal model architectures and build applications, such as image and video-to-text classifiers. Go further by combining different models and platforms and learning about AI agent replication.

## What you will learn
- Learn how to pretrain and fine-tune LLMs
- Learn how to work with multiple platforms, such as Hugging Face, OpenAI, and Google Vertex AI
- Learn about different tokenizers and the best practices for preprocessing language data
- Implement Retrieval Augmented Generation and rules bases to mitigate hallucinations
- Visualize transformer model activity for deeper insights using BertViz, LIME, and SHAP
- Create and implement cross-platform chained models, such as HuggingGPT
- Go in-depth into vision transformers with CLIP, DALL-E 2, DALL-E 3, and GPT-4V


## Table of Contents
### Chapters
1. What Are Transformers?
2. Getting Started with the Architecture of the Transformer Model
3. Emergent vs Downstream Tasks: The Unseen Depths of Transformers
4. Advancements in Translations with Google Trax, Google Translate, and Gemini
5. Diving into Fine-Tuning through BERT
6. Pretraining a Transformer from Scratch through RoBERTa
7. The Generative AI Revolution with ChatGPT
8. Fine-Tuning OpenAI GPT Models
9. Shattering the Black Box with Interpretable Tools
10. Investigating the Role of Tokenizers in Shaping Transformer Models 
11. Leveraging LLM Embeddings as an Alternative to Fine-Tuning
12. Toward Syntax-Free Semantic Role Labeling with ChatGPT and GPT-4
13. Summarization with T5 and ChatGPT
14. Exploring Cutting-Edge LLMs with Vertex AI and PaLM 2
15. Guarding the Giants: Mitigating Risks in Large Language Models
16. Beyond Text: Vision Transformers in the Dawn of Revolutionary AI
17. Transcending the Image-Text Boundary with Stable Diffusion
18. Hugging Face AutoTrain: Training Vision Models without Coding
19. On the Road to Functional AGI with HuggingGPT and its Peers
20. Beyond Human-Designed Prompts with Generative Ideation
### Appendix
Appendix: Answers to the Questions


### Platforms
You can run the notebooks directly from here by clicking on ![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)
| Chapter | Colab | Kaggle | Gradient | StudioLab |
| :-------- | :-------- | :------- |:------- |:------- |
| | | | | |
**Part I The Foundations of Transformer Models**
 **Chapter 1: What are Transformers?**
| <ul><li>O-1_and_Accelerators.ipynb</li><li>ChatGPT_Plus_writes_and_explains_AI.ipynb</li></ul> |[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter01/O_1_and_Accelerators.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter01/ChatGPT_Plus_writes_and_explains_AI.ipynb) |
 **Chapter 2: Getting Started with the Architecture of the Transformer Model**
| <ul><li>Multi_Head_Attention_Sub_Layer.ipynb</li><li>positional_encoding.ipynb</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter02/Multi_Head_Attention_Sub_Layer.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter02/positional_encoding.ipynb) |
 **Chapter 3: Emergent vs Downstream Tasks: the Unseen Depths of Transformers**
| <ul><li>From_training_to_emergence.ipynb</li><li>Transformer_tasks_with_Hugging_Face.ipynb</li></ul> |[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter03/From_training_to_emergence.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter03/Transformer_tasks_with_Hugging_Face.ipynb) |
 **Chapter 4: Advancements in Translations with Google Trax, Google Translate, and Google Bard**
| <ul><li>WMT_translations.ipynb</li><li>Trax_Google_Translate.ipynb</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter04/WMT_translations.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter04/Trax_Google_Translate.ipynb) |
 **Chapter 5: Diving into Fine-Tuning through BERT**
| <ul><li>BERT_Fine_Tuning_Sentence_Classification_GPU.ipynb</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter05/BERT_Fine_Tuning_Sentence_Classification_GPU.ipynb) |
 **Chapter 6: Pretraining a Transformer from Scratch through RoBERTa**
| <ul><li>KantaiBERT.ipynb</li><li>Customer_Support_for_X.ipynb</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter06/KantaiBERT.ipynb)  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter06/Customer_Support_for_X.ipynb)|
 **Part II: The Rise of Suprahuman NLP**
 **Chapter 7: The Generative AI Revolution with ChatGPT**
 | <ul><li>OpenAI_Models.ipynb</li><li>OpenAI_GPT_4_Assistant.ipynb</li><li>Getting_Started_GPT_4_API.ipynb</li><li>GPT_4_RAG.ipynb</li></ul> |[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter07/OpenAI_Models.ipynb)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter07/OpenAI_GPT_4_Assistant.ipynb)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter07/Getting_Started_GPT_4_API.ipynb)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter07/GPT_4_RAG.ipynb)|
 **Chapter 8: Fine-tuning OpenAI Models**
| <ul><li>Fine_tuning_OpenAI_Models.ipynb</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter08/Fine_tuning_OpenAI_Models.ipynb) |
 **Chapter 9: Shattering the Black Box with Interpretable tools**
| <ul><li>BertViz_Interactive.ipynb</li><li>Hugging_Face_SHAP.ipynb</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter09/BertViz_Interactive.ipynb)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter09/Hugging_Face_SHAP.ipynb)
 **Chapter 10: Investigating the Role of Tokenizers in Shaping Transformer Models**
| <ul><li>Tokenizers.ipynb</li><li>Sub_word_tokenizers.ipynb</li><li>Exploring_tokenizers.ipynb</li></ul> |[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter10/Tokenizers.ipynb)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter10/Sub_word_tokenizers.ipynb)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter10/Exploring_tokenizers.ipynb)|
 **Chapter 11: Leveraging LLM Embeddings as an Alternative to Fine-Tuning**
 | <ul><li>Embedding_with_NLKT_Gensim.ipynb</li><li>Question_answering_with_embeddings.ipynb</li><li>Transfer_Learning_with_Ada_Embeddings.ipynb</li></ul> |[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter11/Embedding_with_NLKT_Gensim.ipynb)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter11/Question_answering_with_embeddings.ipynb)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter11/Transfer_Learning_with_Ada_Embeddings.ipynb)|
 **Chapter 12: Towards Syntax-Free Semantic Role Labeling with BERT and OpenAI's ChatGPT**
| <ul><li>Semantic_Role_Labeling_GPT-4.ipynb</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter12/Semantic_Role_Labeling_GPT-4.ipynb)|
 **Chapter 13: Summarization with T5 and ChatGPT**
| <ul><li>Summerizing_Text_T5.ipynb</li><li>Summarizing_ChatGPT.ipynb</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter13/Summerizing_Text_T5.ipynb)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter13/Summarizing_ChatGPT.ipynb)|
 **Chapter 14: Exploring Cutting-Edge NLP with Google Vertex AI and PaLM 2**
| <ul><li>Google_Vertex_AI.ipynb</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter14/Google_Vertex_AI.ipynb) |
 **Chapter 15: Guarding the Giants: Mitigating Risks in Large Language Models**
| <ul><li>Auto_Big_bench.ipynb</li><li>WandB_Prompts_Quickstart.ipynb</li><li>Encoder_decoder_transformer.ipynb</li><li>Mitigating_Generative_AI.ipynb</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter15/Auto_Big_bench.ipynb)  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter15/WandB_Prompts_Quickstart.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter15/Encoder_decoder_transformer.ipynb)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter15/Mitigating_Generative_AI.ipynb)|
 **Part III: Generative Computer Vision: A New Way to See the World**
 **Chapter 16: Vision Transformers in the Dawn of Revolutionary AI**
| <ul><li>ViT_CLIP.ipynb</li><li>Getting_Started_DALL_E_API.ipynb</li><li>GPT-4V.ipynb</li></ul> |[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter16/ViT_CLIP.ipynb)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter16/Getting_Started_DALL_E_API.ipynb)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter16/GPT-4V.ipynb)|
 **Chapter 17: Transcending the Image-Text Boundary with Stable Diffusion**
| <ul><li>Stable_Diffusion_Keras.ipynb</li><li>Stable__Vision_Stability_AI.ipynb</li><li>Stable__Vision_Stability_AI_Animation.ipynb</li><li>Text_to_video_synthesis.ipynb</li><li>TimeSformer.ipynb</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter17/Stable_Diffusion_Keras.ipynb)  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter17/Stable__Vision_Stability_AI.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter17/Stable__Vision_Stability_AI_Animation.ipynb)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter17/Text_to_video_synthesis.ipynb)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter17/TimeSformer.ipynb)|
 **Chapter 18: Automated Vision Transformer Training**
| <ul><li>Hugging_Face_AutoTrain.ipynb</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter18/Hugging_Face_AutoTrain.ipynb) |
 **Chapter 19: On the Road to Functional AGI with HuggingGPT and its Peers**
| <ul><li>Computer_Vision_Analysis.ipynb</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter19/Computer_Vision_Analysis.ipynb) |
 **Chapter 20: Generative AI Ideation Vertex AI, Langchain, and Stable Diffusion**
| <ul><li>Automated_Design.ipynb</li><li>Midjourney_bot.ipynb</li><li>Automated_Ideation.ipynb</li><li>üê¨ MyMidjourney_API.ipynb</li></ul> |[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter20/Automated_Design.ipynb)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter20/Midjourney_bot.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter20/Automated_Ideation.ipynb)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter20/MyMidjourney_API.ipynb)|



### Get my copy
> If you feel this book is for you, get your [copy](https://www.amazon.com/Transformers-Natural-Language-Processing-Computer-ebook/dp/B0CNH9V8M5/) today! <img alt="Coding" height="15" width="35"  src="https://media.tenor.com/ex_HDD_k5P8AAAAi/habbo-habbohotel.gif">


## Software and Hardware List
With the following software and hardware list you can run all code files present in the book

| Chapter | Software required    | Link to the software    | Hardware specifications    | OS required    |
| :---:  | :---: | :---: |:---: | :---: |
| 1-20 | Python 3.8  | https://www.python.org/downloads/   | x86/AMD64 system  |  Windows, any Linux distro, or macOS  |

## Know more on the Discord server <img alt="Coding" height="25" width="32"  src="https://cliply.co/wp-content/uploads/2021/08/372108630_DISCORD_LOGO_400.gif">

You can get more engaged on the discord server for more latest updates and discussions in the community at [Discord](https://www.packt.link/Transformers) 

## Download a free PDF <img alt="Coding" height="25" width="40" src="https://emergency.com.au/wp-content/uploads/2021/03/free.gif">

_If you have already purchased a print or Kindle version of this book, you can get a DRM-free PDF version at no cost. Simply click on the link to claim your_
[Free PDF](https://packt.link/free-ebook/9781805128724) <img alt="Coding" height="15" width="35"  src="https://media.tenor.com/ex_HDD_k5P8AAAAi/habbo-habbohotel.gif">

We also provide a PDF file that has color images of the screenshots/diagrams used in this book at [ColorImages](https://packt.link/gbp/9781805128724) <img alt="Coding" height="15" width="35"  src="https://media.tenor.com/ex_HDD_k5P8AAAAi/habbo-habbohotel.gif">


## Get to Know the Author
Denis Rothman graduated from Sorbonne University and Paris Diderot University, designing one of the first patented encoding and embedding systems. He authored one of the first patented AI cognitive robots and bots. He began his career delivering Natural Language Processing (NLP) chatbots for Mo√´t et Chandon and as an AI tactical defense optimizer for Airbus (formerly Aerospatiale).
Denis then authored an AI resource optimizer for IBM and luxury brands, leading to an Advanced Planning and Scheduling (APS) solution used worldwide.
