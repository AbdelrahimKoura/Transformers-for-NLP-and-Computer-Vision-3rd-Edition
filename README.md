# Transformers_3rd_Edition<br>
<img src="https://github.com/Denis2054/Transformers_3rd_Edition/blob/main/Transformers_book_in_production_image.png?raw=tru" alt="drawing" width="400"/>
book-in-production image copyright 2023, Denis Rothman generated with Midjourney 5.1. prompt on Discord

Last updated: May 18, 2023

üìó**Ready for review**

| Chapter | Colab | Kaggle | Gradient | StudioLab |
| :-------- | :-------- | :------- |:------- |:------- |
| | | | | |
**Part 1 The Foundations of Transformer Models**
 **Chapter 2: Getting Started with the Architecture of the Transformer Model**
| <ul><li>Multi_Head_Attention_Sub_Layer.ipynb</li><li>positional_encoding.ipynb</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers_3rd_Edition/blob/main/Chapter02/Multi_Head_Attention_Sub_Layer.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers_3rd_Edition/blob/main/Chapter02/positional_encoding.ipynb) |
 **Chapter 3: Advancements in Translations with Google Trax, Google Translate, and Google Bard**
| <ul><li>WMT_translations.ipynb</li><li>Trax_Google_Translate.ipynb/li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers_3rd_Edition/blob/main/Chapter04/WMT_translations.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers_3rd_Edition/blob/main/Chapter04/Trax_Google_Translate.ipynb) |
 **Chapter 5: Diving into Fine-Tuning through BERT**
| <ul><li>BERT_Fine_Tuning_Sentence_Classification_GPU.ipynb</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers_3rd_Edition/blob/main/Chapter05/BERT_Fine_Tuning_Sentence_Classification_GPU.ipynb) |
 **Chapter 6: Pretraining a Transformer from Scratch through RoBERTa**
| <ul><li>KantaiBERT.ipynb</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers_3rd_Edition/blob/main/Chapter06/KantaiBERT.ipynb) |

üìò**Work in Progress** 

**Chapter 1: What are Transformers?** <br>
ChatGPT_Plus_writes_and_explains_classification.ipynb  

**Chapter 3: Downstream NLP Tasks with Transformers**  <br> 				
Transformer_tasks.ipynb  <br>   

**Chapter 4: Machine Translation with the Transformer**  <br>   			
Trax_translation.ipynb  <br>   

**Part II The Rise of Suprahuman Transformers**  <br>   

**Chapter 7: The Rise of Suprahuman Transformers with GPT-3 Engines**  <br>   			
Getting_Started_GPT_3.ipynb<br>
Fine_tuning_GPT_3.ipynb<br>
Jump_Starting_ChatGPT_with_the_OpenAI_API.ipynb<br>
Getting_Started_with_GPT_4.ipynb<br>
Speaking_with_ChatGPT.ipynb<br>
üê¨Go back to the origins with GPT-2 and ChatGPT  				
GPT_2_and_ChatGPT_the_Origins.ipynb  
üê¨Explore and compare ChatGPT, GPT-4 and GPT-3 models  				
Exploring_GPT_4_API.ipynb  

**Chapter 8: Embedding**  
Domain_Specific_GPT_3_Functionality.ipynb  

**Chapter 9 : Matching Tokenizers and Datasets**  <br>				
Tokenizers.ipynb<br>
Training_OpenAI_GPT_2_CH09.ipynb<br> 

**Chapter 10 : Applying Transformers to Legal and Financial Documents for AI Text Summarization**<br>  				
Summerizing_Text_with_T5.ipynb<br>
(?)Summarizing_with_ChatGPT.ipynb<br>  

**Chapter 11 : Semantic Role Labeling**<br>  			
SRL.ipynb<br>
Semantic_Role_Labeling_with_ChatGPT.ipynb<br>

**Chapter 12 : Let Your Data Do the Talking: Story, Questions, and Answers** <br>  				
QA.ipynb<br>
01_Basic_QA_Pipeline.ipynb<br>
(x)Haystack_QA_Pipeline.ipynb<br> 

**Chapter 13 Detecting Customer Emotions to Make Predictions** <br>  		
SentimentAnalysis.ipynb  

**Chapter 14 : Analyzing Fake News with Transformers** <br>  			
Fake_News.ipynb<br>
Fake_News_Analysis_with_ChatGPT.ipynb<br>  

**Chapter 15 : Interpreting Black Box Transformer Models** <br>  			
BertViz.ipynb<br>
Understanding_GPT_2_models_with_Ecco.ipynb<br>
üê¨Create a ChatGPT XAI function that explains ChatGPT and an XAI SHAP function  
XAI_by_ChatGPT_for_ChatGPT.ipynb  

**Chapter 16 : The Emergence of Transformer-Driven Copilots**  
KantaiBERT_Recommender.ipynb  
Prompt_Engineering_as_an_alternative_to_fine_tuning.ipynb  
üê¨ChatGPT or davinin_instruct? What is best for your project?  		
ChatGPT_as_a_Cobot_ChatGPT_versus_davinci_instruct.ipynb  
üê¨AI Language Model Comparison  
-Explore various AI language models and their capabilities through this comprehensive notebook  
-Dive into different APIs and functionalities, such as sentiment analysis, entity recognition, syntax analysis, content classification, and AI vision. 
-Discover and compare the offerings of Google Cloud AI Language,Google Cloud AI Vision, OpenAI GPT-4, Google Bard, Microsoft New Bing, ChatGPT Plus-GPT-4,Hugging Face, HuggingGPT, and Google Smart Compose.<br>  	
Exploring_and_Comparing_Advanced_AI_Technologies.ipynb  

**Part III Computer Vision**  

**Chapter 17: From NLP to Task-Agnostic Transformer Models**  <br>
Vision_Transformers.ipynb  
DALL_E.ipynb  
Vision_Transformer_MLP_Mixer.ipynb<br>
DiT, Diffusion Transformer

**Chapter 18: Prompt Art**  
Getting_Started_with_the_DALL_E_2_API.ipynb  

**Chapter 19: Fine-Tuning and training CV**   
Hugging Face  

**Chapter 20: Metaverse**  
ALL_in_One.ipynb  
