{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eKj0dub1XC5"
      },
      "source": [
        "#Fine-Tuning GPT-3\n",
        "\n",
        "Copyright 2023 Denis Rothman\n",
        "\n",
        "[OpenAI fine-tuning documentation](https://beta.openai.com/docs/guides/fine-tuning/)\n",
        "\n",
        "Check the cost of fine-tuning your dataset on OpenAI before running the notebook.\n",
        "\n",
        "Run this notebook cell by cell to:\n",
        "\n",
        "1.prepare data\n",
        "2.fine-tune a model\n",
        "3.run a fine-tuned model\n",
        "4.manage the fine-tunes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9VPzFA02q9Z"
      },
      "source": [
        "## Installing OpenAI & Wandb\n",
        "\n",
        "Restart the runtime after installing openai and run the cell again to make sur that \"import openai\" is executed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maEF3GMf1We6"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import openai\n",
        "except:\n",
        "  !pip install openai\n",
        "  import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bfKMG4M29U4"
      },
      "source": [
        "## Your API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Eb6gFplQqU5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1baf809-b746-4ae1-9737-1fff34617060"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#You can retrieve your API key from a file(1)\n",
        "# or enter it manually(2)\n",
        "\n",
        "#Comment this cell if you want to enter your key manually.\n",
        "#(1)Retrieve the API Key from a file\n",
        "#Store you key in a file and read it(you can type it directly in the notebook but it will be visible for somebody next to you)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "f = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\n",
        "API_KEY=f.readline()\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#(2) Enter your manually by\n",
        "# replacing API_KEY by your key.\n",
        "#The OpenAI Key\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] =API_KEY\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "LwacvzYC5ZxQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cipgQQrUkLfu"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import wandb\n",
        "except:\n",
        "  !pip install wandb\n",
        "  import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-MAI-1E2RJp"
      },
      "source": [
        "# 1.Preparing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Preparing the data in JSON"
      ],
      "metadata": {
        "id": "ll-77RgaeLUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#From Gutenberg to JSON\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import re\n",
        "\n",
        "# First, fetch the text of the book from Project Gutenberg\n",
        "url = 'http://www.gutenberg.org/cache/epub/4280/pg4280.html'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Get the text of the book and clean it up a bit\n",
        "text = soup.get_text()\n",
        "text = re.sub('\\s+', ' ', text).strip()\n",
        "\n",
        "# Split the text into sentences\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "# Define the separator and ending\n",
        "prompt_separator = \" ->\"\n",
        "completion_ending = \"\\n\"\n",
        "\n",
        "# Now create the prompts and completions\n",
        "data = []\n",
        "for i in range(len(sentences) - 1):\n",
        "    data.append({\n",
        "        \"prompt\": sentences[i] + prompt_separator,\n",
        "        \"completion\": \" \" + sentences[i + 1] + completion_ending\n",
        "    })\n",
        "\n",
        "# Write the prompts and completions to a file\n",
        "with open('kant_prompts_and_completions.json', 'w') as f:\n",
        "    for line in data:\n",
        "        f.write(json.dumps(line) + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Yn8Xe1ciRIV",
        "outputId": "f77a53cb-c864-4d19-8b08-e36fb32feff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_json('kant_prompts_and_completions.json', lines=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ut59UvQ5e0ZX",
        "outputId": "23953174-fa76-4ae4-94ec-69603de6f808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 prompt  \\\n",
              "0     The Project Gutenberg Etext of The Critique of...   \n",
              "1     Be sure to check the copyright laws for your c...   \n",
              "2     We encourage you to keep this file, exactly as...   \n",
              "3                         Please do not remove this. ->   \n",
              "4     This header should be the first thing seen whe...   \n",
              "...                                                 ...   \n",
              "6122  78-79. is their motto, under which they may le...   \n",
              "6123  As regards those who wish to pursue a scientif...   \n",
              "6124  When I mention, in relation to the former, the...   \n",
              "6125          The critical path alone is still open. ->   \n",
              "6126  If my reader has been kind and patient enough ...   \n",
              "\n",
              "                                             completion  \n",
              "0      Be sure to check the copyright laws for your ...  \n",
              "1      We encourage you to keep this file, exactly a...  \n",
              "2                          Please do not remove this.\\n  \n",
              "3      This header should be the first thing seen wh...  \n",
              "4      Do not change or edit it without written perm...  \n",
              "...                                                 ...  \n",
              "6122   As regards those who wish to pursue a scienti...  \n",
              "6123   When I mention, in relation to the former, th...  \n",
              "6124           The critical path alone is still open.\\n  \n",
              "6125   If my reader has been kind and patient enough...  \n",
              "6126   End of Project Gutenberg's The Critique of Pu...  \n",
              "\n",
              "[6127 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0dcc6008-aaa6-4cdc-9fc4-03a5b362a903\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>completion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Project Gutenberg Etext of The Critique of...</td>\n",
              "      <td>Be sure to check the copyright laws for your ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Be sure to check the copyright laws for your c...</td>\n",
              "      <td>We encourage you to keep this file, exactly a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>We encourage you to keep this file, exactly as...</td>\n",
              "      <td>Please do not remove this.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Please do not remove this. -&gt;</td>\n",
              "      <td>This header should be the first thing seen wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This header should be the first thing seen whe...</td>\n",
              "      <td>Do not change or edit it without written perm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6122</th>\n",
              "      <td>78-79. is their motto, under which they may le...</td>\n",
              "      <td>As regards those who wish to pursue a scienti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6123</th>\n",
              "      <td>As regards those who wish to pursue a scientif...</td>\n",
              "      <td>When I mention, in relation to the former, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6124</th>\n",
              "      <td>When I mention, in relation to the former, the...</td>\n",
              "      <td>The critical path alone is still open.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6125</th>\n",
              "      <td>The critical path alone is still open. -&gt;</td>\n",
              "      <td>If my reader has been kind and patient enough...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6126</th>\n",
              "      <td>If my reader has been kind and patient enough ...</td>\n",
              "      <td>End of Project Gutenberg's The Critique of Pu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6127 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0dcc6008-aaa6-4cdc-9fc4-03a5b362a903')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0dcc6008-aaa6-4cdc-9fc4-03a5b362a903 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0dcc6008-aaa6-4cdc-9fc4-03a5b362a903');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC5FIgJ37uKB"
      },
      "source": [
        "##  1.2. Converting the data to JSONL\n",
        "\n",
        "Answer \"Y\" to all of the questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8ZoW1Dn5u7x"
      },
      "outputs": [],
      "source": [
        "!openai tools fine_tunes.prepare_data -f \"kant_prompts_and_completions.json\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Open the file and read the lines\n",
        "with open('kant_prompts_and_completions_prepared.jsonl', 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# Parse and print the first 5 lines\n",
        "for line in lines[199:300]:\n",
        "    data = json.loads(line)\n",
        "    print(json.dumps(data, indent=4))"
      ],
      "metadata": {
        "id": "nf30vW4Wizop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERWDRtNu69-4"
      },
      "source": [
        "# 2.Fine-tuning a model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.create -t \"kant_prompts_and_completions_prepared.jsonl\" -m \"ada\""
      ],
      "metadata": {
        "id": "UOSYOb1UkuE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOmhKh3Eofe_"
      },
      "source": [
        "OpenAI has many requests.\n",
        "If your steam is interrupted, OpenAI will indicate the instruction to continue fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Vkowt6topSA"
      },
      "outputs": [],
      "source": [
        "# Uncomment this cell to activate the fine_tunes 'follow' instruction\n",
        "#!openai api fine_tunes.follow -i [YOUR_FINE_TUNE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeJsz10c776f"
      },
      "source": [
        "# 3.Running the fine-tuned GPT-3 model\n",
        "\n",
        "We will now run the model for a completion task\n",
        "\n",
        "Note: If your fine-tuned model does not appear immediately after the end of the fine-tuning process, you might have to wait until it is processed by OpenAI. You can also:\n",
        "\n",
        "1.go to the OpenAI Playground to test your model: https://platform.openai.com/playground\n",
        "\n",
        "2.select your model in the dropdown list and test it in that environment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"drive/MyDrive/files/fine_tune.txt\", \"r\")\n",
        "FINE_TUNE=f.readline().strip() #load your saved model from a file or load it in this variable\n",
        "f.close()\n",
        "FINE_TUNE"
      ],
      "metadata": {
        "id": "ntuBwjIN5I13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Freedom can be a concept or a virtue ->\"\n",
        "response=openai.Completion.create(\n",
        "  model=FINE_TUNE, #Your model in FINE_TUNE,\n",
        "  prompt=prompt,\n",
        "  temperature=1,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=\"\\n\",\n",
        "  max_tokens=200\n",
        ")"
      ],
      "metadata": {
        "id": "_p0ObKX4SEAo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "oWnmae8ll0FU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "generated_text = response['choices'][0]['text']\n",
        "\n",
        "# Remove leading and trailing whitespace\n",
        "generated_text = generated_text.strip()\n",
        "\n",
        "# Convert to a pretty paragraph by replacing newline characters with spaces\n",
        "single_line_response = generated_text.replace('\\n', ' ')\n",
        "\n",
        "# Use textwrap.fill to nicely format the paragraph to wrap at 80 characters (or whatever width you prefer)\n",
        "wrapped_response = textwrap.fill(single_line_response, width=80)\n",
        "print(wrapped_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpeSFrqrmYBn",
        "outputId": "782d2322-9b26-4bdc-c122-31553e4009b3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At first glance, solely through our language, none of these conceptions better\n",
            "than their opposites—that is, in an empirical intuition.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCZ52flvqVF0"
      },
      "source": [
        "# 4.Managing the fine_tunes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xrf68bD2Nxug"
      },
      "outputs": [],
      "source": [
        "# List all created fine-tunes\n",
        "!openai api fine_tunes.list > fine_tunes.json\n",
        "!openai api fine_tunes.list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ChatGPT PLUS, GPT-4 provides a  breakdown of the components of the JSON object**\n",
        "\n",
        "- `\"object\"`: This line specifies the type of object the JSON is representing. Here it's a fine-tuned model.\n",
        "\n",
        "- `\"id\"`: This is the unique identifier for this fine-tuning job. This ID is typically used to reference this specific instance of fine-tuning.\n",
        "\n",
        "- `\"hyperparams\"`: These are the hyperparameters used for fine-tuning the model.\n",
        "   - `\"n_epochs\"`: Number of epochs for the training, i.e., how many times the learning algorithm will work through the entire training dataset.\n",
        "   - `\"batch_size\"`: The number of training examples used in one iteration (or update) of model parameters.\n",
        "   - `\"prompt_loss_weight\"`: This is the weight assigned to the loss function of the prompts during training. A higher value places more emphasis on minimizing the loss of the prompts.\n",
        "   - `\"learning_rate_multiplier\"`: This value is used to scale the learning rate during training. A lower value will cause the model to learn slower and vice versa.\n",
        "\n",
        "- `\"organization_id\"`: This is the identifier for the organization account under which the fine-tuning operation was performed.\n",
        "\n",
        "- `\"model\"`: The base model used for fine-tuning. In your case, it's `ada`, which is a version of GPT-3.\n",
        "\n",
        "- `\"training_files\"`: This array contains information about the files used for training.\n",
        "  - `\"object\"`: Specifies the object type, in this case, a file.\n",
        "  - `\"id\"`: The unique identifier for this file.\n",
        "  - `\"purpose\"`: The purpose of the file, here it's for fine-tuning.\n",
        "  - `\"filename\"`: The name of the file.\n",
        "  - `\"bytes\"`: The size of the file in bytes.\n",
        "  - `\"created_at\"`: The UNIX timestamp for when the file was created.\n",
        "  - `\"status\"`: The status of the file processing. Here it's processed.\n",
        "  - `\"status_details\"`: Any extra details about the file's status. It's null here, meaning there are no extra details.\n",
        "\n",
        "- `\"validation_files\"`: This would include similar details as `\"training_files\"`, but for any files used for validation during training. It's empty in your case.\n",
        "\n",
        "- `\"result_files\"`: This is an array of files that store the result of the fine-tuning operation. The details of each file are similar to those in `\"training_files\"`.\n",
        "\n",
        "- `\"created_at\"`: The UNIX timestamp indicating when this fine-tuning job was created.\n",
        "\n",
        "- `\"updated_at\"`: The UNIX timestamp indicating the last time this fine-tuning job was updated.\n",
        "\n",
        "- `\"status\"`: The status of the fine-tuning job. In this case, it has succeeded.\n",
        "\n",
        "- `\"fine_tuned_model\"`: This is the unique identifier/name for the fine-tuned model.\n",
        "  \n",
        "Remember that a UNIX timestamp is the number of seconds that have passed since 00:00:00 Thursday, 1 January 1970, minus leap seconds. Programs like Python's datetime library can convert these to more human-readable formats."
      ],
      "metadata": {
        "id": "juaVC4fgxQnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.FineTune.retrieve(\"ft-daprSZy6dWb7KlN6WQxOeS0Y\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "xPUBg-3d-VAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Load data from json file\n",
        "with open('fine_tunes.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Convert to Pandas DataFrame:\n",
        "df = pd.json_normalize(data['data'])\n",
        "\n",
        "# Select specific columns\n",
        "selected_columns = ['object', 'id', 'fine_tuned_model','status', 'created_at', 'updated_at']\n",
        "df = df[selected_columns]\n",
        "\n",
        "# Rename columns for display\n",
        "column_mapping = {\n",
        "    'object': 'Object',\n",
        "    'id': 'ID',\n",
        "    'fine_tuned_model': 'Fine_Tuned_Model',\n",
        "    'filename':'Filename',\n",
        "    'status': 'Status',\n",
        "    'created_at': 'Created_At',\n",
        "    'updated_at': 'Updated_At',\n",
        "}\n",
        "df.rename(columns=column_mapping, inplace=True)\n",
        "\n",
        "# Convert UNIX timestamp to standard format\n",
        "df['Created_At'] = pd.to_datetime(df['Created_At'], unit='s')\n",
        "df['Updated_At'] = pd.to_datetime(df['Updated_At'], unit='s')\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "e4N3bVAC7GNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#delete a model\n",
        "# enter a model in the list of fine-tuned models\n",
        "#FINE_TUNED_MODEL=[MODEL in list]\n",
        "#try:\n",
        "#  openai.Model.delete(FINE_TUNED_MODEL)\n",
        "#except:\n",
        "#  print(\"FINE_TUNED_MODEL not found\")"
      ],
      "metadata": {
        "id": "osfqQ0-479dB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}