{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPM-W5IVxfJS"
      },
      "source": [
        "# Getting Started with GPT-3 Engines\n",
        "\n",
        "copyright 2021-2023 Denis Rothman\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image     #This is used for rendering images in the notebook"
      ],
      "metadata": {
        "id": "1yf-ju9P62Zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7HO_zOAaA-Y"
      },
      "source": [
        "## Step 1: Installing & importing OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS_Qk62FxclT"
      },
      "source": [
        "try:\n",
        "  import openai\n",
        "except:\n",
        "  !pip install openai\n",
        "  import openai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnKbbxVMaYqy"
      },
      "source": [
        "## Step 2: Entering the API KEY"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21LhKHnrxA5l",
        "outputId": "6c76c225-7a80-4c38-c7a6-353a98e959d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\n",
        "API_KEY=f.readline()\n",
        "f.close()"
      ],
      "metadata": {
        "id": "k8cmujpyxKjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authentification\n",
        "\n",
        "Setting the environment variable OPENAI_API_KEY to the value of API_KEY"
      ],
      "metadata": {
        "id": "PTD5NZ4Ox-G4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] =API_KEY\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "NAzxa-GRx8Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6d0bggZX_dw"
      },
      "source": [
        "## Step 3: Running an NLP tasks with the default parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKwqIwACcB2B"
      },
      "source": [
        "## Step 4: Example 1: Grammar correction\n",
        "\n",
        "https://beta.openai.com/examples/default-grammar\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pkZrsEzzNwS"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=\"Original: She no went to the market.\\nStandard American English:\",\n",
        "  temperature=0,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  logprobs=5,\n",
        "  stop=[\"\\n\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieving the value of \"text\" in the dicionary\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "id": "cpWrXf0LU3k6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33ed893d-9ac7-4845-c998-96adb85b7e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " She didn't go to the market.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh1AuRliZVfS"
      },
      "source": [
        "## Example 2: Translation\n",
        "\n",
        "https://beta.openai.com/examples/default-translate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXh8vAb3M2ob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab984ea4-ff27-4b8b-a278-2dfd20c3aa9b"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=\"Original: She no went to the market.\\n French with no contractions:\",\n",
        "  temperature=0,\n",
        "  max_tokens=60,\n",
        "  top_p=0.95,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  logprobs=5,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "response"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-7XWNCOxEoLTwZWIIlDKUt5VKJj9j6 at 0x7f40c0eed440> JSON: {\n",
              "  \"id\": \"cmpl-7XWNCOxEoLTwZWIIlDKUt5VKJj9j6\",\n",
              "  \"object\": \"text_completion\",\n",
              "  \"created\": 1688223622,\n",
              "  \"model\": \"davinci\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"text\": \" Elle n'est pas all\\u00e9e au march\\u00e9.\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": {\n",
              "        \"tokens\": [\n",
              "          \" El\",\n",
              "          \"le\",\n",
              "          \" n\",\n",
              "          \"'\",\n",
              "          \"est\",\n",
              "          \" pas\",\n",
              "          \" all\",\n",
              "          \"\\u00e9e\",\n",
              "          \" au\",\n",
              "          \" march\",\n",
              "          \"\\u00e9\",\n",
              "          \".\"\n",
              "        ],\n",
              "        \"token_logprobs\": [\n",
              "          -0.057429295,\n",
              "          -0.00072578347,\n",
              "          -0.34465164,\n",
              "          -0.3763348,\n",
              "          -0.17710593,\n",
              "          -0.021533938,\n",
              "          -0.014351609,\n",
              "          -0.060334742,\n",
              "          -0.06209631,\n",
              "          -0.045513622,\n",
              "          -0.0021425916,\n",
              "          -0.028863197\n",
              "        ],\n",
              "        \"top_logprobs\": [\n",
              "          {\n",
              "            \" She\": -4.5160666,\n",
              "            \"\\n\": -5.618727,\n",
              "            \" Ce\": -6.107749,\n",
              "            \" El\": -0.057429295,\n",
              "            \"El\": -5.8028092\n",
              "          },\n",
              "          {\n",
              "            \"lem\": -10.502332,\n",
              "            \"le\": -0.00072578347,\n",
              "            \" l\": -10.887599,\n",
              "            \" e\": -7.7413335,\n",
              "            \" ne\": -10.728477\n",
              "          },\n",
              "          {\n",
              "            \" est\": -2.6832404,\n",
              "            \" a\": -4.234895,\n",
              "            \" n\": -0.34465164,\n",
              "            \" ne\": -1.7631735,\n",
              "            \" no\": -3.8789268\n",
              "          },\n",
              "          {\n",
              "            \" est\": -7.414039,\n",
              "            \"bytes:\\\\xe2\\\\x80\": -1.181461,\n",
              "            \"'\": -0.3763348,\n",
              "            \"`\": -7.1233253,\n",
              "            \" '\": -6.827499\n",
              "          },\n",
              "          {\n",
              "            \" est\": -4.51838,\n",
              "            \"est\": -0.17710593,\n",
              "            \"all\": -5.8445096,\n",
              "            \"a\": -2.4324427,\n",
              "            \"y\": -3.0000772\n",
              "          },\n",
              "          {\n",
              "            \" pa\": -8.401247,\n",
              "            \" pas\": -0.021533938,\n",
              "            \" j\": -5.118328,\n",
              "            \" all\": -4.7543445,\n",
              "            \" point\": -5.8557816\n",
              "          },\n",
              "          {\n",
              "            \" venue\": -5.980225,\n",
              "            \" non\": -6.716469,\n",
              "            \" alle\": -5.594197,\n",
              "            \" all\": -0.014351609,\n",
              "            \" revenue\": -7.3665733\n",
              "          },\n",
              "          {\n",
              "            \" \": -6.249543,\n",
              "            \"\\u00e9e\": -0.060334742,\n",
              "            \"er\": -5.802518,\n",
              "            \"\\u00e9\": -3.364225,\n",
              "            \"\\u00c3\": -6.272233\n",
              "          },\n",
              "          {\n",
              "            \" a\": -6.92894,\n",
              "            \" aux\": -5.8728065,\n",
              "            \" \\u00e0\": -2.9737327,\n",
              "            \" d\": -7.380165,\n",
              "            \" au\": -0.06209631\n",
              "          },\n",
              "          {\n",
              "            \" mar\": -4.490513,\n",
              "            \" market\": -4.341122,\n",
              "            \" mag\": -5.098839,\n",
              "            \" super\": -4.917198,\n",
              "            \" march\": -0.045513622\n",
              "          },\n",
              "          {\n",
              "            \".\": -7.8550205,\n",
              "            \"\\u00e8\": -8.346735,\n",
              "            \"\\u00e9e\": -8.755392,\n",
              "            \"\\u00e9\": -0.0021425916,\n",
              "            \"\\u00c9\": -8.573\n",
              "          },\n",
              "          {\n",
              "            \".\": -0.028863197,\n",
              "            \"\\n\": -4.9848185,\n",
              "            \" (\": -5.507859,\n",
              "            \"..\": -6.4680486,\n",
              "            \"\\n\\n\": -5.115472\n",
              "          }\n",
              "        ],\n",
              "        \"text_offset\": [\n",
              "          66,\n",
              "          69,\n",
              "          71,\n",
              "          73,\n",
              "          74,\n",
              "          77,\n",
              "          81,\n",
              "          85,\n",
              "          87,\n",
              "          90,\n",
              "          96,\n",
              "          97\n",
              "        ]\n",
              "      },\n",
              "      \"finish_reason\": \"stop\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 16,\n",
              "    \"completion_tokens\": 12,\n",
              "    \"total_tokens\": 28\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "id": "HdYTg9XNGeG8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45fa1c58-6cf5-4485-887d-66b57a2ebe45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Elle n'est pas allée au marché.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KMUpe35ZA-t"
      },
      "source": [
        "## Example 3: Instruct series\n",
        "\n",
        "https://beta.openai.com/docs/engines/instruct-series-beta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2oL0NLRNI3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a740294f-20a1-4339-b5ae-4ef90c31c8fe"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci-instruct-beta\",\n",
        "  prompt=\"Write a plan of actions based on these instructions:\\n\\nStart Internet Explorer.\\nYou need to eventually click on the advanced tab.\\nBut before that, click on the Internet options on the tools menu.\\nAfter the click on the advanced tab, click to clear or select the enable\\npersonalized favorite menu check box.\\n\\n\\nACTIONS:\",\n",
        "  temperature=0,\n",
        "  max_tokens=120,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Start Internet Explorer.\n",
            "2. Click on the tools menu.\n",
            "3. Click on the Internet options.\n",
            "4. Click on the advanced tab.\n",
            "5. Click to clear or select the enable personalized favorite menu check box.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWGCjioUawKp"
      },
      "source": [
        "## Example 4: Movie to emoji\n",
        "\n",
        "https://beta.openai.com/examples/default-movie-to-emoji"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUOH-fAbawlc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "873b0735-e9cc-4d12-c1bf-3b6aa2169f32"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=\"Back to Future: 👨👴🚗🕒\\nBatman: 🤵🦇\\nTransformers: 🚗🤖\\nWonder Woman: 👸🏻👸🏼👸🏽👸🏾👸🏿\\nWinnie the Pooh: 🐻🐼🐻\\nThe Godfather: 👨👩👧🕵🏻‍♂️👲💥\\nGame of Thrones: 🏹🗡🗡🏹\\nSpider-Man:\",\n",
        "  temperature=0.8,\n",
        "  max_tokens=60,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 👊🏻👊🏽👊🏾👊🏿️\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8QgB1Phg0_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afab3d8b-820a-4019-8869-0a2d6635f7ab"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=\"Back to Future: 👨👴🚗🕒\\nBatman: 🤵🦇\\nTransformers: 🚗🤖\\nWonder Woman: 👸🏻👸🏼👸🏽👸🏾👸🏿\\nWinnie the Pooh: 🐻🐼🐻\\nThe Godfather: 👨👩👧🕵🏻‍♂️👲💥\\nGame of Thrones: 🏹🗡🗡🏹\\nSpider-Man: 🕷🕸🕷🕸\\nAvatar:\",\n",
        "  temperature=0.8,\n",
        "  max_tokens=60,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 👨🏻🎥👩🏻👨🏻\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrS3kT-ebaT9"
      },
      "source": [
        "## Example 5: Programming language to another language. For example: Python to Javascript\n",
        "\n",
        "https://beta.openai.com/examples/default-js-to-py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPIDVEVfbZ1x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5268e4f-15f1-4ff4-b804-5dead4c04c1f"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=\"##### Translate this function  from Python into Javascript\\n### Python\\n    \\n    def predict_proba(X: Iterable[str]):\\n        return np.array([predict_one_probas(tweet) for tweet in X])\\n    \\n### Javascript\\n    \\n    function predict_proba(X: Iterable[str]):\\n        return np.array([predict_one_probas(tweet) for tweet in X])\\n\\n# Now we can use the function in Javascript\\n%%\",\n",
        "  temperature=0,\n",
        "  max_tokens=54,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"###\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time\n",
            "predict_proba(X)\n",
            "# Output:\n",
            "# [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNY5uUu6ead0"
      },
      "source": [
        "## Example 6: Advanced Tweet classifier\n",
        "\n",
        "https://beta.openai.com/examples/default-tweet-classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDeD3FkbearQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e58677d-1b64-4995-a3b5-eacbc63629fe"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=\"This is a tweet sentiment classifier\\nTweet: \\\"I loved the new Batman movie!\\\"\\nSentiment: Positive\\n###\\nTweet: \\\"I hate it when my phone battery dies\\\"\\nSentiment: Negative\\n###\\nTweet: \\\"My day has been 👍\\\"\\nSentiment: Positive\\n###\\nTweet: \\\"This is the link to the article\\\"\\nSentiment: Neutral\\n###\\nTweet text\\n\\n\\n1. \\\"I loved the new Batman movie!\\\"\\n2. \\\"I hate it when my phone battery dies\\\"\\n3. \\\"My day has been 👍\\\"\\n4. \\\"This is the link to the article\\\"\\n5. \\\"This new music video blew my mind\\\"\\n\\n\\nTweet sentiment ratings:\\n1: Positive\\n2: Negative\\n3: Positive\\n4: Neutral\\n5: Positive\\n\\n\\n###\\nTweet text\\n\\n\\n1. \\\"I can't stand homework\\\"\\n2. \\\"This sucks. I'm bored 😠\\\"\\n3. \\\"I can't wait for Halloween!!!\\\"\\n4. \\\"My cat is adorable ❤️❤️\\\"\\n5. \\\"I hate chocolate\\\"\\n\\n\\nTweet sentiment ratings:\\n1.\",\n",
        "  temperature=0.3,\n",
        "  max_tokens=60,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"###\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Negative\n",
            "2. Negative\n",
            "3. Positive\n",
            "4. Positive\n",
            "5. Negative\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=\"This is a tweet sentiment classifier\\nSentence: \\\"What does semiotics mean?\\\"\\n\\nA: \",\n",
        "  temperature=0,\n",
        "  max_tokens=100,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "id": "hIR6AhJhFvEE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80c3ed21-c303-421f-e89e-891cbed0790e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \"semiotics is the study of signs and symbols\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-Qiw1mjcmd6"
      },
      "source": [
        "## Example 7: Q&A\n",
        "\n",
        "https://beta.openai.com/examples/default-qa\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh9hcKvrcobu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6c97ec5-d483-4231-8eb5-d63012160e34"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=\"Q: What does semiotics mean?\\nA: Semiotics is the study of signs and symbols.\\n\\nA: \",\n",
        "  temperature=0,\n",
        "  max_tokens=100,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The semiotic square is a tool used to analyze the relationships between signs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P6zd0J8dYuT"
      },
      "source": [
        "## Example 8 : Summarize a text\n",
        "\n",
        "https://beta.openai.com/examples/default-summarize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyLOtqjkdZGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "155fc0e6-d636-4c0d-a7b7-2f416424273f"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=\"My second grader asked me what this passage means:\\n\\\"\\\"\\\"\\nJupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. It is named after the Roman god Jupiter.[19] When viewed from Earth, Jupiter can be bright enough for its reflected light to cast visible shadows,[20] and is on average the third-brightest natural object in the night sky after the Moon and Venus.\\n\\\"\\\"\\\"\\nI rephrased it for him, in plain language a second grader can understand:\\n\\\"\\\"\\\"\\n\",\n",
        "  temperature=0.5,\n",
        "  max_tokens=100,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0.2,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\\"\\\"\\\"\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jupiter is a large planet. It has a mass that is one thousandth that of the Sun, but two and a half times more than all the other planets in the Solar System combined. Jupiter is a very bright object in the night sky, and it has been known to people since before recorded history.\n",
            "Jupiter is named after the Roman god Jupiter. When viewed from Earth, Jupiter can be bright enough for its light to cast shadows, and it is usually the third brightest object in the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr5vvsGzdvKA"
      },
      "source": [
        "## Example 9: Parse unstructured data\n",
        "\n",
        "https://beta.openai.com/examples/default-parse-data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9g8n0Zfdviy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8131c89d-2c23-4617-e41d-2c8573d276f2"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=\"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy. There are also loheckles, which are a grayish blue fruit and are very tart, a little bit like a lemon. Pounits are a bright green color and are more savory than sweet. There are also plenty of loopnovas which are a neon pink flavor and taste like cotton candy. Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\\n\\nPlease make a table summarizing the fruits from Goocrux\\n| Fruit | Color | Flavor |\\n| Neoskizzles | Purple | Sweet |\\n| Loheckles | Grayish blue | Tart |\\n\",\n",
        "  temperature=0,\n",
        "  max_tokens=100,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\n\\n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Pounits | Bright green | Savory |\n",
            "| Loopnovas | Neon pink | Cotton candy |\n",
            "| Glowls | Pale orange | Sour |\n",
            "| Other | |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1WLppo5eDhg"
      },
      "source": [
        "## Example 10 : Calculate Time Complexity\n",
        "\n",
        "https://beta.openai.com/examples/default-time-complexity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfvgh8sseDxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c21738af-59ab-4806-8e34-338cc23b5b2e"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=\"def foo(n, k):\\naccum = 0\\nfor i in range(n):\\n    for l in range(k):\\n        accum += i\\nreturn accum\\n\\\"\\\"\\\"\\nThe time complexity of this function is\",\n",
        "  temperature=0,\n",
        "  max_tokens=64,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " O(nk).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZetplCF_gEny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3031c3a3-0592-4c91-8b90-3cb8b0bd5751"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=\"A single column spreadsheet of industry names:\\n\\n\\nIndustry|\\nAccounting/Finance\\nAdvertising/Public Relations\\nAerospace/Aviation\\nArts/Entertainment/Publishing\\nAutomotive\\nBanking/Mortgage\\nBusiness Development\\nBusiness Opportunity\\nClerical/Administrative\\nConstruction/Facilities\\nConsumer Goods\\nCustomer Service\\nEducation/Training\\nEnergy/Utilities\\nEngineering\\nGovernment/Military\\nGreen\\n\\n\\n###\\n\\n\\nA spreadsheet of top science fiction movies and the year of release:\\n\\n\\nTitle|Year\\nStar Wars|1977\\nJaws|1975\\nThe Exorcist|1973\\nET|1982\\nAliens|1986\\nTerminator|1984\\nBlade Runner|1982\\nThe Thing|1982\\nJurassic Park|1993\\nThe Matrix|1999\\n\\n\\n###\\n\\n\\nA spreadsheet of hurricane and tropical storm counts with 13 columns:\\n\\n\\n\\\"Month\\\"| \\\"Average\\\"| \\\"2005\\\"| \\\"2006\\\"| \\\"2007\\\"| \\\"2008\\\"| \\\"2009\\\"| \\\"2010\\\"| \\\"2011\\\"| \\\"2012\\\"| \\\"2013\\\"| \\\"2014\\\"| \\\"2015\\\"\\n\\\"May\\\"|  0.1|  0|  0| 1| 1| 0| 0| 0| 2| 0|  0|  0  \\n\\\"Jun\\\"|  0.5|  2|  1| 1| 0| 0| 1| 1| 2| 2|  0|  1\\n\\\"Jul\\\"|  0.7|  5|  1| 1| 2| 0| 1| 3| 0| 2|  2|  1\\n\\\"Aug\\\"|  2.3|  6|  3| 2| 4| 4| 4| 7| 8| 2|  2|  3\\n\\\"Sep\\\"|  3.5|  6|  4| 7| 4| 2| 8| 5| 2| 5|  2|  5\\n\\\"Oct\\\"|  2.0|  8|  0| 1| 3| 2| 5| 1| 5| 2|  3|  0\\n\\\"Nov\\\"|  0.5|  3|  0| 0| 1| 1| 0| 1| 0| 1|  0|  1\\n\\\"Dec\\\"|  0.0|  1|  0| 1| 0| 0| 0| 0| 0| 0|  0|  1\\n    \\n###\\n\\n\\nA single column spreadsheet of days of the week:\\n\\n\\nDay|\\nMonday\\nTuesday\\nWednesday\\nThursday\\nFriday\\nSaturday\\nSunday\\n\\n\\n###\\n\\n\\nA two column spreadsheet of computer languages and their difficulty level:\",\n",
        "  temperature=0.3,\n",
        "  max_tokens=60,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"/n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Language|Difficulty\n",
            "C| Intermediate\n",
            "Java| Easy\n",
            "Python| Easy\n",
            "Ruby| Easy\n",
            "Perl| Intermediate\n",
            "PHP| Easy\n",
            "Lisp| Hard\n",
            "Scala| Hard\n",
            "Haskell| Hard\n",
            "Clojure| Hard\n",
            "Erlang| Hard\n",
            "\n",
            "###\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Playground for Q&A"
      ],
      "metadata": {
        "id": "8gRxAyBn09g7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "Gcu6gnkB0511"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ask a question and finish the question with a start_sequence = \"\\nA:\"\n",
        "\n",
        "For example:\n",
        "\n",
        "What is the capital of italy?\\nA:\n",
        "\n",
        "Make sure to add the start sequence \"\\nA\""
      ],
      "metadata": {
        "id": "JmaVh0u915Ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import openai\n",
        "\n",
        "def generate_response(prompt):\n",
        "    response = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        temperature=0,\n",
        "        max_tokens=100,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0,\n",
        "        stop=[\"\\n\"]\n",
        "    )\n",
        "\n",
        "    r = (response[\"choices\"][0])\n",
        "    return r[\"text\"]\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=generate_response,\n",
        "    inputs=gr.inputs.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n",
        "    outputs=\"text\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "B3459Ew61Xmw",
        "outputId": "44e34778-6d65-456a-98b3-95c4516ca9bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:30: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  super().__init__(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:30: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  super().__init__(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}