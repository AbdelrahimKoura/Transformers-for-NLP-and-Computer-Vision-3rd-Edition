{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYvzs7cLR9oY"
      },
      "source": [
        "# Vertex AI\n",
        "Copyright 2024, Denis Rothman\n",
        "\n",
        "Google, as other editors advancing at full speed with LLM generative transformer models, is continually updating the available models.\n",
        "\n",
        "The models versions may not be stable. If you encounter an issue, go to Google's model versioning page to see which use.\n",
        "\n",
        "https://cloud.google.com/vertex-ai/docs/generative-ai/learn/model-versioning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRWWL_vpNZpg"
      },
      "outputs": [],
      "source": [
        "import textwrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoDSC70YVXog",
        "outputId": "a8229759-dcd9-42b2-ae9c-4c69b744fbc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.39.0)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.11.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (23.2)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.12.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.11.0)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.62.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.17.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.31.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.60.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.48.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.0)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.23.5)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2023.11.17)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwmwszyXSr9l"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()\n",
        "\n",
        "import vertexai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnCHBV8LJhmq"
      },
      "source": [
        "# Question Answering(QA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_6EDI6AJjfT"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview.language_models import ChatModel, InputOutputTextPair\n",
        "\n",
        "vertexai.init(project=\"aiex-57523\", location=\"us-central1\")\n",
        "chat_model = ChatModel.from_pretrained(\"chat-bison@001\")\n",
        "parameters = {\n",
        "    \"temperature\": 0.2,\n",
        "    \"max_output_tokens\": 256,\n",
        "    \"top_p\": 0.8,\n",
        "    \"top_k\": 40\n",
        "}\n",
        "chat = chat_model.start_chat(\n",
        "    context=\"\"\"Answer a question on the text submitted\"\"\",\n",
        ")\n",
        "response = chat.send_message(\"\"\"Based on the following text, Does Gemini repeat existing text or does it produce new text?\"\"\", **parameters)\n",
        "\n",
        "wrapped_text=textwrap.fill(response.text, width=40)\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M9lPXAJShrC"
      },
      "source": [
        "# Question Answering(QA) - general"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvfFMN5ySyd3",
        "outputId": "21d7f728-a7c9-4806-e74c-551953a3396e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am powered by PaLM 2, which stands for\n",
            "Pathways Language Model 2, a large\n",
            "language model from Google AI.\n"
          ]
        }
      ],
      "source": [
        "from vertexai.preview.language_models import ChatModel, InputOutputTextPair\n",
        "\n",
        "def predict_large_language_model_sample(\n",
        "    project_id: str,\n",
        "    model_name: str,\n",
        "    temperature: float,\n",
        "    max_output_tokens: int,\n",
        "    top_p: float,\n",
        "    top_k: int,\n",
        "    location: str = \"us-central1\",\n",
        "    ) :\n",
        "    \"\"\"Predict using a Large Language Model.\"\"\"\n",
        "    vertexai.init(project=project_id, location=location)\n",
        "\n",
        "    chat_model = ChatModel.from_pretrained(model_name)\n",
        "    parameters = {\n",
        "      \"temperature\": temperature,\n",
        "      \"max_output_tokens\": max_output_tokens,\n",
        "      \"top_p\": top_p,\n",
        "      \"top_k\": top_k,\n",
        "    }\n",
        "\n",
        "    chat = chat_model.start_chat(\n",
        "      examples=[]\n",
        "    )\n",
        "    response=chat.send_message('''What Transformer model are you using for this conversation?''',**parameters)\n",
        "    #print(response.text)\n",
        "    wrapped_text=textwrap.fill(response.text, width=40)\n",
        "    print(wrapped_text)\n",
        "\n",
        "\n",
        "predict_large_language_model_sample(\"aiex-57523\", \"chat-bison@001\", 0.2, 256, 0.8, 40, \"us-central1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7Iggtu8SrI2"
      },
      "source": [
        "# Summarization of a conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJoN4TsxnjK6",
        "outputId": "a3816e63-1923-4067-8b3f-d1806bef7fb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The customer wants to change the\n",
            "shipping address for an order. The\n",
            "service rep informs the customer that\n",
            "the order has already shipped and they\n",
            "will need to contact the shipping\n",
            "provider to update their delivery\n",
            "details.\n"
          ]
        }
      ],
      "source": [
        "import vertexai\n",
        "from vertexai.language_models import TextGenerationModel\n",
        "\n",
        "vertexai.init(project=\"aiex-57523\", location=\"us-central1\")\n",
        "parameters = {\n",
        "    \"temperature\": 0.2,\n",
        "    \"max_output_tokens\": 256,\n",
        "    \"top_p\": 0.8,\n",
        "    \"top_k\": 40\n",
        "}\n",
        "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "response = model.predict(\n",
        "    \"\"\"Summarize the following conversation between a service rep and a customer in a few sentences. Use only the information from the conversation.\n",
        "\n",
        "Service Rep: How may I assist you today?\n",
        "Customer: I need to change the shipping address for an order.\n",
        "Service Rep: Ok, I can help you with that if the order has not been fulfilled from our warehouse yet. But if it has already shipped, then you will need to contact the shipping provider. Do you have the order ID?\n",
        "Customer: Yes, it\\'s 88986367.\n",
        "Service Rep: One minute please while I pull up your order information.\n",
        "Customer: No problem\n",
        "Service Rep: Ok, it looks like your order was shipped from our warehouse 2 days ago. It is now in the hands of  the shipping provider, so you will need to contact them to update your delivery details. You can track your order with the shipping provider here: https://www.shippingprovider.com\n",
        "Customer: Sigh, ok.\n",
        "Service Rep: Is there anything else I can help you with today?\n",
        "Customer: No, thanks.\"\"\",\n",
        "    **parameters\n",
        ")\n",
        "#print(f\"Response from Model: {response.text}\")\n",
        "wrapped_text=textwrap.fill(response.text, width=40)\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyaLZEkoS4W_"
      },
      "source": [
        "# Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQgm5sNDnxOD",
        "outputId": "f70e4f84-47a2-4933-a510-340296f1318f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "positive\n"
          ]
        }
      ],
      "source": [
        "from vertexai.language_models import TextGenerationModel\n",
        "\n",
        "vertexai.init(project=\"aiex-57523\", location=\"us-central1\")\n",
        "parameters = {\n",
        "    \"temperature\": 0.2,\n",
        "    \"max_output_tokens\": 256,\n",
        "    \"top_p\": 0.8,\n",
        "    \"top_k\": 40\n",
        "}\n",
        "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "response = model.predict(\n",
        "    \"\"\"Is the sentiment positive or negative towards Louis van Gaal based on the article:\n",
        "\n",
        "Article:\n",
        "Louis van Gaal said he had no option but to substitute Paddy McNair in the first half against Southampton because the defender\\'s \\'confidence\\' was shot - but believes that it will benefit the youngster in the long run.\n",
        "The 19-year-old was hooked by Van Gaal after only 39 minutes at St Mary\\'s Stadium on Monday night during Manchester United\\'s 2-1 victory over the Saints.\n",
        "McNair was struggling to contain Southampton strikers Shane Long and Graziano Pelle, forcing Van Gaal into replacing him prematurely.\n",
        "Speaking to Sky Sports after the match, Van Gaal explained: \\'He (McNair) hadn\\'t any confidence. He had already given three big chances away.\n",
        "\\'I had to (substitute him), it\\'s very disappointing for me and also for Paddy, but I had to because as a manager, I\\'m responsible to win.\n",
        "\\'And I think, after the change, we played a little better.\\'\n",
        "But in spite of the fact United won the game, McNair was exposed time after time in defence and was substituted - even though Chris Smalling had already departed early with an injury.\n",
        "Jonny Evans came on to replace Smalling, before McNair made way for midfielder Ander Herrera as Michael Carrick dropped back in to the centre of defence in Van Gaal\\'s 3-5-2 system.\n",
        "And, despite admitting it will be difficult for McNair to accept being replaced so early, Van Gaal insisted that it was a necessity which will serve the Northern Irishman well long term.\n",
        "Van Gaal continued: \\'Of course, it\\'s tough (for McNair), but it\\'s also in his best interests.\\'\n",
        "The victory moved United up to third in the Premier League - their highest position since they claimed the title in 2012-13 under Sir Alex Ferguson. \"\"\",\n",
        "    **parameters\n",
        ")\n",
        "#print(f\"Response from Model: {response.text}\")\n",
        "wrapped_text=textwrap.fill(response.text, width=40)\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IeUFdFGWSAp",
        "outputId": "fd9173c8-c1e6-4afd-cfd4-71fdb65d197f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment towards Louis van Gaal is\n",
            "positive.  The article is about Louis\n",
            "van Gaal's decision to substitute Paddy\n",
            "McNair in the first half of the match\n",
            "against Southampton. The article says\n",
            "that Van Gaal had to make the\n",
            "substitution because McNair was\n",
            "struggling and had given away three big\n",
            "chances. Van Gaal also says that he\n",
            "thinks the substitution was the right\n",
            "thing to do and that it will benefit\n",
            "McNair in the long run.  The article\n",
            "also says that Van Gaal is responsible\n",
            "for winning the match, and that he\n",
            "believes the substitution helped United\n",
            "to play better.  Overall, the article\n",
            "presents Van Gaal in a positive light.\n",
            "He is portrayed as a manager who is\n",
            "willing to make tough decisions in order\n",
            "to win, and who is looking out for the\n",
            "best interests of his players.\n"
          ]
        }
      ],
      "source": [
        "from vertexai.language_models import TextGenerationModel\n",
        "\n",
        "vertexai.init(project=\"aiex-57523\", location=\"us-central1\")\n",
        "parameters = {\n",
        "    \"temperature\": 0.2,\n",
        "    \"max_output_tokens\": 256,\n",
        "    \"top_p\": 0.8,\n",
        "    \"top_k\": 40\n",
        "}\n",
        "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "response = model.predict(\n",
        "    \"\"\"Is the sentiment positive or negative towards Louis van Gaal based on the article and explain why in detail:\n",
        "\n",
        "Article:\n",
        "Louis van Gaal said he had no option but to substitute Paddy McNair in the first half against Southampton because the defender\\'s \\'confidence\\' was shot - but believes that it will benefit the youngster in the long run.\n",
        "The 19-year-old was hooked by Van Gaal after only 39 minutes at St Mary\\'s Stadium on Monday night during Manchester United\\'s 2-1 victory over the Saints.\n",
        "McNair was struggling to contain Southampton strikers Shane Long and Graziano Pelle, forcing Van Gaal into replacing him prematurely.\n",
        "Speaking to Sky Sports after the match, Van Gaal explained: \\'He (McNair) hadn\\'t any confidence. He had already given three big chances away.\n",
        "\\'I had to (substitute him), it\\'s very disappointing for me and also for Paddy, but I had to because as a manager, I\\'m responsible to win.\n",
        "\\'And I think, after the change, we played a little better.\\'\n",
        "But in spite of the fact United won the game, McNair was exposed time after time in defence and was substituted - even though Chris Smalling had already departed early with an injury.\n",
        "Jonny Evans came on to replace Smalling, before McNair made way for midfielder Ander Herrera as Michael Carrick dropped back in to the centre of defence in Van Gaal\\'s 3-5-2 system.\n",
        "And, despite admitting it will be difficult for McNair to accept being replaced so early, Van Gaal insisted that it was a necessity which will serve the Northern Irishman well long term.\n",
        "Van Gaal continued: \\'Of course, it\\'s tough (for McNair), but it\\'s also in his best interests.\\'\n",
        "The victory moved United up to third in the Premier League - their highest position since they claimed the title in 2012-13 under Sir Alex Ferguson. \"\"\",\n",
        "    **parameters\n",
        ")\n",
        "#print(f\"Response from Model: {response.text}\")\n",
        "wrapped_text=textwrap.fill(response.text, width=40)\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rilcm2bGS-sC"
      },
      "source": [
        "# Multi-choice problems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfMQS2dqoBoF",
        "outputId": "7338c86f-7bdd-4a93-ad38-8762d3c8af13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "culture\n"
          ]
        }
      ],
      "source": [
        "from vertexai.language_models import TextGenerationModel\n",
        "\n",
        "vertexai.init(project=\"aiex-57523\", location=\"us-central1\")\n",
        "parameters = {\n",
        "    \"temperature\": 0.2,\n",
        "    \"max_output_tokens\": 256,\n",
        "    \"top_p\": 0.8,\n",
        "    \"top_k\": 40\n",
        "}\n",
        "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "response = model.predict(\n",
        "    \"\"\"Multi-choice problem: What is the topic of this text?\n",
        "- entertainment\n",
        "- technology\n",
        "- politics\n",
        "- sports\n",
        "- business\n",
        "- health\n",
        "- fun\n",
        "- culture\n",
        "- science\n",
        "\n",
        "Text: Samba, is a name or prefix used for several rhythmic variants, such as samba urbano carioca (urban Carioca samba), samba de roda (sometimes also called rural samba), recognized as part of the Intangible Cultural Heritage of Humanity by UNESCO, amongst many other forms of Samba, mostly originated in the Rio de Janeiro and Bahia States. Samba is a broad term for many of the rhythms that compose the better known Brazilian music genres that originated in the Afro-Brazilian communities of Bahia in the late 19th century and early 20th century, having continued its development on the communities of Rio de Janeiro in the early 20th century. Having its roots in the Afro-Brazilian Candomblé, as well as other Afro-Brazilian and Indigenous folk traditions, such as the traditional Samba de Caboclo, it is considered one of the most important cultural phenomena in Brazil and one of the country\\'s symbols. Present in the Portuguese language at least since the 19th century, the word \\\"samba\\\" was originally used to designate a \\\"popular dance\\\". Over time, its meaning has been extended to a \\\"batuque-like circle dance\\\", a dance style, and also to a \\\"music genre\\\". This process of establishing itself as a musical genre began in the 1910s and it had its inaugural landmark in the song \\\"Pelo Telefone\\\", launched in 1917. Despite being identified by its creators, the public, and the Brazilian music industry as \\\"samba\\\", this pioneering style was much more connected from the rhythmic and instrumental point of view to maxixe than to samba itself.\n",
        "\n",
        "Samba was modernly structured as a musical genre only in the late 1920s from the neighborhood of Estácio and soon extended to Oswaldo Cruz and other parts of Rio through its commuter rail. Today synonymous with the rhythm of samba, this new samba brought innovations in rhythm, melody and also in thematic aspects. Its rhythmic change based on a new percussive instrumental pattern resulted in a more \\\"batucado\\\" and syncopated style – as opposed to the inaugural \\\"samba-maxixe\\\" – notably characterized by a faster tempo, longer notes and a characterized cadence far beyond the simple ones palms used so far. Also the \\\"Estácio paradigm\\\" innovated in the formatting of samba as a song, with its musical organization in first and second parts in both melody and lyrics. In this way, the sambistas of Estácio created, structured and redefined the urban Carioca samba as a genre in a modern and finished way. In this process of establishment as an urban and modern musical expression, the Carioca samba had the decisive role of samba schools, responsible for defining and legitimizing definitively the aesthetic bases of rhythm, and radio broadcasting, which greatly contributed to the diffusion and popularization of the genre and its song singers. Thus, samba has achieved major projection throughout Brazil and has become one of the main symbols of Brazilian national identity. Once criminalized and rejected for its Afro-Brazilian origins, and definitely working-class music in its mythic origins, the genre has also received support from members of the upper classes and the country\\'s cultural elite.\"\"\",\n",
        "    **parameters\n",
        ")\n",
        "#print(f\"Response from Model: {response.text}\")\n",
        "wrapped_text=textwrap.fill(response.text, width=40)\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsxGgCS5XjBv"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw2TkOsGXkiV",
        "outputId": "cc3bd6c1-6152-4e4e-b824-6cbb6605f35c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response from Model: Sure, here is the code for a function in Python that calculates a Fibonacci suite up to 10:\n",
            "\n",
            "```python\n",
            "def fibonacci(n):\n",
            "  \"\"\"Calculates the nth Fibonacci number.\n",
            "\n",
            "  Args:\n",
            "    n: The index of the Fibonacci number to calculate.\n",
            "\n",
            "  Returns:\n",
            "    The nth Fibonacci number.\n",
            "  \"\"\"\n",
            "\n",
            "  if n == 0:\n",
            "    return 0\n",
            "  elif n == 1:\n",
            "    return 1\n",
            "  else:\n",
            "    return fibonacci(n - 1) + fibonacci(n - 2)\n",
            "\n",
            "```\n",
            "\n",
            "This function works by recursively calling itself to calculate the Fibonacci numbers up to the desired index. The base cases are when `n == 0` and `n == 1`, which return 0 and 1, respectively. For all other values of `n`, the function returns the sum of the previous two Fibonacci numbers.\n"
          ]
        }
      ],
      "source": [
        "from vertexai.preview.language_models import CodeChatModel\n",
        "\n",
        "vertexai.init(project=\"aiex-57523\", location=\"us-central1\")\n",
        "chat_model = CodeChatModel.from_pretrained(\"codechat-bison@001\")\n",
        "parameters = {\n",
        "    \"temperature\": 0.5,\n",
        "    \"max_output_tokens\": 1024\n",
        "}\n",
        "chat = chat_model.start_chat()\n",
        "response = chat.send_message(\"\"\"Write the code in Python for a function in Python that calculates a Fibonacci  suite up to 10:\"\"\", **parameters)\n",
        "print(f\"Response from Model: {response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmExDk96XqqJ"
      },
      "source": [
        "copy code into cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHM1bskUXtGc"
      },
      "outputs": [],
      "source": [
        "def fibonacci(n):\n",
        "  \"\"\"\n",
        "  This function calculates the Fibonacci sequence up to the given number.\n",
        "\n",
        "  Args:\n",
        "    n: The number to calculate the Fibonacci sequence up to.\n",
        "\n",
        "  Returns:\n",
        "    The Fibonacci sequence up to the given number.\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialize the sequence with 0 and 1.\n",
        "  a = 0\n",
        "  b = 1\n",
        "\n",
        "  # Iterate through the sequence, calculating each new number.\n",
        "  for i in range(n):\n",
        "    # Calculate the next number in the sequence.\n",
        "    c = a + b\n",
        "\n",
        "    # Update the sequence.\n",
        "    a = b\n",
        "    b = c\n",
        "\n",
        "  # Return the sequence.\n",
        "  return a, b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZwHyuSHXyZr"
      },
      "source": [
        "call the function and run the code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIZLkZvwXyAA",
        "outputId": "e341a3b7-9aec-4471-ae1e-4412549dd050"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(55, 89)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fibonacci(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsuEsPSsDd0k",
        "outputId": "5c2ce668-8134-4c20-e55e-01b908c6f3e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response from Model: ```python\n",
            "from vertexai.preview.language_models import CodeChatModel\n",
            "\n",
            "vertexai.init(project=\"aiex-57523\", location=\"us-central1\")\n",
            "chat_model = CodeChatModel.from_pretrained(\"codechat-bison@001\")\n",
            "parameters = {\n",
            "    \"temperature\": 0.5,\n",
            "    \"max_output_tokens\": 1024\n",
            "}\n",
            "chat = chat_model.start_chat()\n",
            "response = chat.send_message(\"\"\"Write the code in Python for a function in Python that calculates a Fibonacci  suite up to 10:\"\"\", **parameters)\n",
            "print(f\"Response from Model: {response.text}\")\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "import vertexai\n",
        "from vertexai.preview.language_models import CodeGenerationModel\n",
        "\n",
        "vertexai.init(project=\"aiex-57523\", location=\"us-central1\")\n",
        "parameters = {\n",
        "    \"temperature\": 0.2,\n",
        "    \"max_output_tokens\": 1024\n",
        "}\n",
        "model = CodeGenerationModel.from_pretrained(\"code-bison@001\")\n",
        "response = model.predict(\n",
        "    prefix = \"\"\"Correct the following code in Python that calculates a Fibonacci suite up to 10 numbers starting from 0 or 1. The code is inaccurate because it calculates 11 numbers instead of 10. Provide a corrected code:from vertexai.preview.language_models import CodeChatModel\n",
        "\n",
        "vertexai.init(project=\\\"aiex-57523\\\", location=\\\"us-central1\\\")\n",
        "chat_model = CodeChatModel.from_pretrained(\\\"codechat-bison@001\\\")\n",
        "parameters = {\n",
        "    \\\"temperature\\\": 0.5,\n",
        "    \\\"max_output_tokens\\\": 1024\n",
        "}\n",
        "chat = chat_model.start_chat()\n",
        "response = chat.send_message(\\\"\\\"\\\"Write the code in Python for a function in Python that calculates a Fibonacci  suite up to 10:\\\"\\\"\\\", **parameters)\n",
        "print(f\\\"Response from Model: {response.text}\\\")\"\"\",\n",
        "    **parameters\n",
        ")\n",
        "print(f\"Response from Model: {response.text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSmbU3ztFk9v",
        "outputId": "31bfe6fa-bc53-42b3-f7d4-8094dc70bc8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "55\n"
          ]
        }
      ],
      "source": [
        "def fibonacci(n):\n",
        "  \"\"\"Calculates the nth Fibonacci number.\n",
        "\n",
        "  Args:\n",
        "    n: The nth Fibonacci number to calculate.\n",
        "\n",
        "  Returns:\n",
        "    The nth Fibonacci number.\n",
        "  \"\"\"\n",
        "  if n == 0:\n",
        "    return 0\n",
        "  elif n == 1:\n",
        "    return 1\n",
        "  else:\n",
        "    return fibonacci(n - 1) + fibonacci(n - 2)\n",
        "\n",
        "\n",
        "print(fibonacci(10))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}